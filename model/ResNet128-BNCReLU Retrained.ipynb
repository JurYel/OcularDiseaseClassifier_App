{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "Crt-3o2sca51"
   },
   "source": [
    "# Import External Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-17T15:32:47.504999Z",
     "iopub.status.busy": "2022-02-17T15:32:47.504604Z",
     "iopub.status.idle": "2022-02-17T15:32:47.575334Z",
     "shell.execute_reply": "2022-02-17T15:32:47.574636Z",
     "shell.execute_reply.started": "2022-02-17T15:32:47.504966Z"
    },
    "id": "k6LQQ1h8ZHL3",
    "outputId": "f6e74ab8-4834-4a97-9487-f7b39c939b6c"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# visualization dependencies\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plotly.offline import iplot, plot\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "import cufflinks as cf\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=False)\n",
    "\n",
    "init_notebook_mode(connected=False)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120.0\n",
    "plt.rcParams['font.sans-serif'] = 'Lato'\n",
    "sns.set(style='whitegrid', palette='muted',\n",
    "              rc={'figure.figsize': (16, 16)})\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-17T15:32:50.195882Z",
     "iopub.status.busy": "2022-02-17T15:32:50.195604Z",
     "iopub.status.idle": "2022-02-17T15:32:50.200104Z",
     "shell.execute_reply": "2022-02-17T15:32:50.199412Z",
     "shell.execute_reply.started": "2022-02-17T15:32:50.195852Z"
    },
    "id": "BDswmC6eymMW"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "LR = 1e-4\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-17T15:32:50.202026Z",
     "iopub.status.busy": "2022-02-17T15:32:50.201638Z",
     "iopub.status.idle": "2022-02-17T15:32:50.213452Z",
     "shell.execute_reply": "2022-02-17T15:32:50.212818Z",
     "shell.execute_reply.started": "2022-02-17T15:32:50.201985Z"
    },
    "id": "EOh36kgodgmA"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def configure_plotly_browser_state():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "    <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "    <script>\n",
    "      requirejs.config({\n",
    "        path: {\n",
    "          base: '/static/base',\n",
    "          plotly: \"https://cdn.plot.ly/plotly-1.5.1.min.js?noext\",\n",
    "        },\n",
    "      });\n",
    "    </script>\n",
    "  '''))\n",
    "\n",
    "def clear_content(directory):\n",
    "  for file in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, file)\n",
    "    try:\n",
    "      if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "        os.unlink(file_path)\n",
    "      elif os.path.isdir(file_path):\n",
    "        shutil.rmtree(file_path)\n",
    "    except Exception as exc:\n",
    "      raise(\"Failed to Delete: %s %s\" % (file_path, exc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "3DyJwnz6ilGD"
   },
   "source": [
    "# Step 1: Load and Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:38:15.595998Z",
     "iopub.status.busy": "2022-02-17T15:38:15.595322Z",
     "iopub.status.idle": "2022-02-17T15:38:58.787498Z",
     "shell.execute_reply": "2022-02-17T15:38:58.786691Z",
     "shell.execute_reply.started": "2022-02-17T15:38:15.595957Z"
    }
   },
   "outputs": [],
   "source": [
    "!conda install -y gdown\n",
    "!gdown --id 1r0k6CsrwWAQKY-pfMPJjvq8f9VOo6wYs\n",
    "!gdown --id 1tkO_BML_6zEb6wNAGYfX7ro_EtJDyrjG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:39:42.965691Z",
     "iopub.status.busy": "2022-02-17T15:39:42.965170Z",
     "iopub.status.idle": "2022-02-17T15:39:49.638385Z",
     "shell.execute_reply": "2022-02-17T15:39:49.637593Z",
     "shell.execute_reply.started": "2022-02-17T15:39:42.965652Z"
    }
   },
   "outputs": [],
   "source": [
    "!gdown --id 1-749mKKw7du1verM4MNsTKXQcGkICEQf\n",
    "!gdown --id 1mTG7Sj9ouZ49lLJFZTtEMM4Ryal4PIQ6\n",
    "!gdown --id 1VmPc29YY3ScYySmuPXSIqtd1L2DtvXB-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:33:46.523771Z",
     "iopub.status.busy": "2022-02-17T15:33:46.523489Z",
     "iopub.status.idle": "2022-02-17T15:33:52.996970Z",
     "shell.execute_reply": "2022-02-17T15:33:52.995914Z",
     "shell.execute_reply.started": "2022-02-17T15:33:46.523730Z"
    },
    "id": "TMUIcksxjwZF",
    "outputId": "72318054-d8c8-4424-e7cf-1e35799d5853"
   },
   "outputs": [],
   "source": [
    "!gdown --id 1XLClixZesnrPoF_wANWWEPtZZeR1_ZtH\n",
    "!gdown --id 1zGkHR7lf6fZpuA3G49T3WqeOng_CjYiV # rgb_merged_model\n",
    "!gdown --id 10k7GKAJIWjcLXPX8V6OfPWHTUWYomDlJ # test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-17T15:33:52.999132Z",
     "iopub.status.busy": "2022-02-17T15:33:52.998829Z",
     "iopub.status.idle": "2022-02-17T15:34:00.265779Z",
     "shell.execute_reply": "2022-02-17T15:34:00.264979Z",
     "shell.execute_reply.started": "2022-02-17T15:33:52.999091Z"
    },
    "id": "3TtTklbbjwZJ",
    "outputId": "07e92456-64e7-474e-d594-1a48bffd2ab6"
   },
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T15:34:00.269826Z",
     "iopub.status.busy": "2022-02-17T15:34:00.269128Z",
     "iopub.status.idle": "2022-02-17T15:34:00.546793Z",
     "shell.execute_reply": "2022-02-17T15:34:00.544764Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.269791Z"
    },
    "id": "liLYUszsjwZL",
    "outputId": "1124b3e0-fd8d-4c01-b818-30ef732e98ae"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "prep_path = \"/kaggle/working/preprocessed_images.zip\"\n",
    "odir_path = \"/kaggle/working/ocular-disease-recognition-odir5k.zip\"\n",
    "\n",
    "paths = ['ocular_dataset_jpg.zip','Glaucoma.zip','ocular_dataset_jpg_400.zip','datazet.zip','ocular-disease-recognition-odir5k.zip', 'preprocessed_images.zip', 'odir_rgb_merged_model_four-0.9248.zip']\n",
    "names = ['ocular_dataset_jpg','Glaucoma','ocular_dataset_jpg_400','datazet','odir5k', 'preprocessed_images', 'odir_rgb_merged_model_four-0.9248']\n",
    "\n",
    "for i in range(7):\n",
    "    if os.path.exists(names[i]):\n",
    "        clear_content(names[i])\n",
    "    else:\n",
    "        os.mkdir(names[i])\n",
    "        \n",
    "    with ZipFile(paths[i], 'r') as obj:\n",
    "        file_list = obj.namelist()\n",
    "        for file in tqdm(file_list):\n",
    "            obj.extract(file, names[i])\n",
    "    print()\n",
    "    print(f\"{names[i]} Data extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.547969Z",
     "iopub.status.idle": "2022-02-17T15:34:00.548449Z",
     "shell.execute_reply": "2022-02-17T15:34:00.548240Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.548215Z"
    }
   },
   "outputs": [],
   "source": [
    "from lib2to3.pygram import Symbols\n",
    "import random\n",
    "import numbers\n",
    "\n",
    "upper = \"ABCEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "lower = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "numbers = \"0123456789\"\n",
    "symbols = \"[]{}()*;/,.@$\"\n",
    "\n",
    "all = lower + symbols + upper + numbers \n",
    "length = 16\n",
    "passcode = \"\".join(random.sample(all, length))\n",
    "print(passcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.550136Z",
     "iopub.status.idle": "2022-02-17T15:34:00.550867Z",
     "shell.execute_reply": "2022-02-17T15:34:00.550655Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.550631Z"
    }
   },
   "outputs": [],
   "source": [
    "for dirname, subfolders, filenames in os.walk(\"/kaggle/working/Glaucoma\"):\n",
    "  for subf in subfolders:\n",
    "    print(os.path.join(dirname, subf))\n",
    "    \n",
    "print(len(os.listdir(\"Glaucoma/Glaucoma\")))\n",
    "# print(len(os.listdir(\"datazet/datazet/glaucoma\")))\n",
    "# print(len(os.listdir(\"datazet/datazet/myopia\")))\n",
    "# print(len(os.listdir(\"datazet/datazet/cataract\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.552194Z",
     "iopub.status.idle": "2022-02-17T15:34:00.552653Z",
     "shell.execute_reply": "2022-02-17T15:34:00.552446Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.552422Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = \"odir5k/ODIR-5K/ODIR-5K/Training Images\"\n",
    "test_dir = \"odir5k/ODIR-5K/ODIR-5K/Testing Images\"\n",
    "# occ_path = \"ocular_dataset_jpg/occ_preprocessed_jpg\"\n",
    "# occ_annot_path = \"ocular_dataset_jpg_/ocular_disease_annotation_upsample.csv\"\n",
    "occ_path = \"ocular_dataset_jpg_400/occ_preprocessed_jpg\"\n",
    "occ_annot_path = \"ocular_dataset_jpg_400/ocular_disease_annotation_upsample.csv\"\n",
    "annotations_path = \"odir5k/full_df.csv\"\n",
    "glaucoma_ds = \"Glaucoma/Glaucoma\"\n",
    "prep_train = \"preprocessed_images/preprocess_train\"\n",
    "prep_test = \"preprocessed_images/preprocess_test\"\n",
    "discarded_path = \"DiscardedImages.xlsx\"\n",
    "test_folder = \"datazet/datazet\"\n",
    "# odir_model_dir = \"odir_model_eight-0.9059/trained_models/odir\"\n",
    "# odir_model_dir = \"odir_model_eight-0.9059/trained_models/odir/odir_model-0.91\"\n",
    "# odir_dir = \"odir_model_eight-0.9059/trained_models/odir\"\n",
    "# odir_model_path = \"odir_model_four-0.9407/trained_models/odir/odir_model-0.94\"\n",
    "# odir_rgb_model_path = \"RGB_odir_model_four-0.9162/trained_models/odir/odir_model-0.92\"\n",
    "odir_model_merged = \"/kaggle/working/odir_rgb_merged_model_four-0.9248/trained_models/odir/odir_model-0.92\"\n",
    "odir_history_merged = \"/kaggle/working/odir_rgb_merged_model_four-0.9248/trained_models/odir/odir_history.h5\"\n",
    "files_train = sorted(os.listdir(train_dir))\n",
    "files_test = sorted(os.listdir(test_dir))\n",
    "glaucoma_data = sorted(os.listdir(glaucoma_ds))\n",
    "\n",
    "print(\"train: \" , len(files_train))\n",
    "print(\"test: \", len(files_test))\n",
    "print(\"occ: \", len(os.listdir(occ_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.554419Z",
     "iopub.status.idle": "2022-02-17T15:34:00.554834Z",
     "shell.execute_reply": "2022-02-17T15:34:00.554639Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.554616Z"
    }
   },
   "outputs": [],
   "source": [
    "folders = ['normal', 'cataract','myopia', 'glaucoma']\n",
    "def remove_non_img(directory):\n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        if os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "        elif os.path.isfile(file_path):\n",
    "            if not file_path.endswith('.png') and not file_path.endswith('.jpg'):\n",
    "                os.unlink(file_path)\n",
    "            \n",
    "for n in range(4):\n",
    "    direc = os.path.join(test_folder, folders[n])\n",
    "#     print(direc)\n",
    "    remove_non_img(direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.556142Z",
     "iopub.status.idle": "2022-02-17T15:34:00.556537Z",
     "shell.execute_reply": "2022-02-17T15:34:00.556343Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.556321Z"
    },
    "id": "kaB9azXQjwZV",
    "outputId": "21a0cf9f-babf-4737-e50e-ab149bc65ed8"
   },
   "outputs": [],
   "source": [
    "len(os.listdir(prep_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "5m_9KlCulG2U"
   },
   "source": [
    "### Visualize Retinal Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.557828Z",
     "iopub.status.idle": "2022-02-17T15:34:00.558256Z",
     "shell.execute_reply": "2022-02-17T15:34:00.558053Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.558030Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "for i in range(25):\n",
    "  rand_idx = np.random.randint(0, len(glaucoma_data))\n",
    "  image = cv2.imread(os.path.join(glaucoma_ds, glaucoma_data[rand_idx]))\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  plt.subplot(5, 5, i+1)\n",
    "  plt.imshow(image)\n",
    "  plt.title(f\"{image.shape}\")\n",
    "  plt.axis('off')\n",
    "  plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.559827Z",
     "iopub.status.idle": "2022-02-17T15:34:00.560258Z",
     "shell.execute_reply": "2022-02-17T15:34:00.560052Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.560029Z"
    },
    "id": "yriy32KJjwZY"
   },
   "outputs": [],
   "source": [
    "# pandas filtering functions\n",
    "\n",
    "def data_mapping(df, initial, odir=True):\n",
    "  labels = []\n",
    "  \n",
    "  if odir:\n",
    "    fundus_names = list(df.iloc[:, 3])\n",
    "  elif not odir:\n",
    "    fundus_names = list(df.iloc[:, 0])\n",
    "\n",
    "  for i in range(len(fundus_names)):\n",
    "    labels.append(initial)\n",
    "\n",
    "  return labels\n",
    "\n",
    "def count_labels(df, odir=True):\n",
    "  if odir:\n",
    "#       labels = list(df.iloc[:, -12:-4].sum().index)\n",
    "    labels = [\"N\", \"C\", \"G\", \"M\"]\n",
    "  elif not odir:\n",
    "    labels = list(df.iloc[:, 1:5].sum().index)\n",
    "#   labels = ['N', 'C']\n",
    "  total_count = []\n",
    "  labels_count = []\n",
    "\n",
    "  for i in range(len(labels)):\n",
    "    label_count = data_mapping(df.loc[(df[labels[i]] == 1)], labels[i], odir)\n",
    "    total_count += label_count\n",
    "    labels_count.append(len(label_count))\n",
    "    print(f\"{labels[i]}: {len(label_count)}\")\n",
    "\n",
    "  return total_count, labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.561495Z",
     "iopub.status.idle": "2022-02-17T15:34:00.561890Z",
     "shell.execute_reply": "2022-02-17T15:34:00.561698Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.561676Z"
    }
   },
   "outputs": [],
   "source": [
    "annot_df = pd.read_csv(annotations_path)\n",
    "occ_df = pd.read_csv(occ_annot_path)\n",
    "occ_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.563232Z",
     "iopub.status.idle": "2022-02-17T15:34:00.563651Z",
     "shell.execute_reply": "2022-02-17T15:34:00.563447Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.563423Z"
    }
   },
   "outputs": [],
   "source": [
    "occ_df.iloc[:, 1:5].sum().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.565162Z",
     "iopub.status.idle": "2022-02-17T15:34:00.565557Z",
     "shell.execute_reply": "2022-02-17T15:34:00.565365Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.565343Z"
    },
    "id": "RbDxSfresTNg",
    "outputId": "4a710ade-f293-4c7a-edfc-1f83838608b1"
   },
   "outputs": [],
   "source": [
    "annot_df.iloc[:, -12:-4].sum().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.566848Z",
     "iopub.status.idle": "2022-02-17T15:34:00.567270Z",
     "shell.execute_reply": "2022-02-17T15:34:00.567071Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.567049Z"
    }
   },
   "outputs": [],
   "source": [
    "annot_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.568463Z",
     "iopub.status.idle": "2022-02-17T15:34:00.569063Z",
     "shell.execute_reply": "2022-02-17T15:34:00.568844Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.568821Z"
    },
    "id": "s1crqdI6jwZc",
    "outputId": "981d57ff-1d33-47fb-ecdc-6ac149802a3a"
   },
   "outputs": [],
   "source": [
    "discarded_sheet = pd.read_excel(discarded_path, sheet_name=\"Sheet1\")\n",
    "# annot_df.loc[(annot_df[\"Left-Fundus\"].isin(discarded_sheet[\"Left-Fundus\"]))].drop(discarded_sheet['Left-Fundus'], axis=0)\n",
    "dropped = annot_df.loc[~annot_df['Left-Fundus'].isin(discarded_sheet['Left-Fundus'])]\n",
    "print(len(dropped.loc[(dropped['Left-Fundus'].isin(discarded_sheet['Left-Fundus']))]))\n",
    "print(len(dropped.loc[(dropped['Left-Fundus'].str.match(\"4601_left.jpg\"))]))\n",
    "\n",
    "# ---- these below are not working ---- #\n",
    "# duplicates = pd.merge(annot_df['Left-Fundus'], discarded_sheet['Left-Fundus'],\n",
    "#                       how='inner', left_on=['Left-Fundus'], right_on=['Left-Fundus'],\n",
    "#                       left_index=True)\n",
    "# dropped = annot_df.loc[(annot_df['Left-Fundus'].isin(discarded_sheet['Left-Fundus']))].drop(\"Left-Fundus\", axis=0)\n",
    "# dropped = annot_df.drop(duplicates.index, axis=0)\n",
    "# dropped = annot_df['Left-Fundus'].drop(discarded_sheet['Left-Fundus'])\n",
    "# dropped.loc[(dropped['Left-Fundus'].isin(discarded_sheet['Left-Fundus']))]\n",
    "# left_eyes = list(discarded_sheet.iloc[:, 1])\n",
    "# len(left_eyes)\n",
    "# annot_df.loc[(annot_df['Left-Diagnostic Keywords'].str.contains(\"|\".join([\"lens dust\", \"low image\", \"anterior\", \"optic disk\", \"refractive\"])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.570372Z",
     "iopub.status.idle": "2022-02-17T15:34:00.570772Z",
     "shell.execute_reply": "2022-02-17T15:34:00.570577Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.570551Z"
    },
    "id": "xqjaQkaSjwZd",
    "outputId": "ce6a97d9-1056-41d6-eb29-2f7fd0194393"
   },
   "outputs": [],
   "source": [
    "# drop occluded and unclear images\n",
    "discarded_sheet = pd.read_excel(discarded_path, sheet_name=\"Sheet1\")\n",
    "disc_tokens = [\"low image\", \"lens dust\", \"anterior\", \"refractive\",\"invisible\",\"image\", \"image offset\",\"chorioretinopathy\"]\n",
    "\n",
    "annot_df_ = annot_df.loc[~annot_df['Left-Fundus'].isin(discarded_sheet['Left-Fundus'])]\n",
    "annot_df = annot_df.loc[~annot_df['Right-Fundus'].isin(discarded_sheet['Right-Fundus'])]\n",
    "annot_df = annot_df.loc[(~annot_df['Left-Diagnostic Keywords'].str.\n",
    "                         contains(\"|\".join(disc_tokens)))]\n",
    "annot_df = annot_df.loc[(~annot_df['Right-Diagnostic Keywords'].str.\n",
    "                         contains(\"|\".join(disc_tokens)))]\n",
    "# test if such exist\n",
    "print(len(annot_df.loc[(annot_df['Left-Diagnostic Keywords'].str.\n",
    "                        contains(\"|\".join(disc_tokens)))]))\n",
    "len(annot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.572080Z",
     "iopub.status.idle": "2022-02-17T15:34:00.572507Z",
     "shell.execute_reply": "2022-02-17T15:34:00.572303Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.572280Z"
    }
   },
   "outputs": [],
   "source": [
    "total_count, labels_count = count_labels(annot_df, True)\n",
    "print('-'*10)\n",
    "occ_total_count, occ_labels_count = count_labels(occ_df, False)\n",
    "total_count += occ_total_count\n",
    "labels_count = [(l1+l2) for l1, l2 in zip(labels_count, occ_labels_count)]\n",
    "print(labels_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "e5px3rgMtkG9"
   },
   "source": [
    "### Retinal Image Distribution per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.573868Z",
     "iopub.status.idle": "2022-02-17T15:34:00.574337Z",
     "shell.execute_reply": "2022-02-17T15:34:00.574091Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.574069Z"
    },
    "id": "SMagGaXwr3DF",
    "outputId": "0cce5707-7425-4b2f-aef5-9d77d5d0f7f0"
   },
   "outputs": [],
   "source": [
    "init_notebook_mode(connected=False)\n",
    "configure_plotly_browser_state()\n",
    "\n",
    "labels_ser = pd.Series(total_count, name='label')\n",
    "labels_df = pd.DataFrame({\n",
    "    'labels': labels_ser.value_counts().index,\n",
    "    \"count\": labels_ser.value_counts()\n",
    "})\n",
    "\n",
    "label_count = sorted(labels_count, reverse=True)\n",
    "labels_df['percentage'] = [float(i / sum(label_count)) for i in label_count]\n",
    "print(labels_df['percentage'])\n",
    "\n",
    "fig = plt.figure(figsize=(30, 14))\n",
    "fig = go.Figure(data=[go.Bar(\n",
    "                x=labels_df['labels'],\n",
    "                y=labels_df['count'],\n",
    "                text=labels_df['percentage'].apply(lambda x: \"{0:1.2f}%\".format(x * 100)),\n",
    "                textposition='auto',\n",
    "                marker=dict(\n",
    "                    colorscale='Viridis'\n",
    "                )                \n",
    "              )])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Fundus Image Distribution',\n",
    "    xaxis_title='diseases',\n",
    "    yaxis_title='count',\n",
    "    font=dict(\n",
    "        size=13\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2022-02-17T15:34:00.575606Z",
     "iopub.status.idle": "2022-02-17T15:34:00.576014Z",
     "shell.execute_reply": "2022-02-17T15:34:00.575807Z",
     "shell.execute_reply.started": "2022-02-17T15:34:00.575785Z"
    },
    "id": "WSprH7KwuDIt",
    "outputId": "fc77297e-a788-4149-f531-a2018519ebfc"
   },
   "outputs": [],
   "source": [
    "sns.countplot(total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdRJ7FvxjwZm"
   },
   "source": [
    "#### Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28WSYn9rjwZm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRd-ZbhfjwZo",
    "outputId": "a89412cc-1594-4554-dd5e-14a8dc232cdc"
   },
   "outputs": [],
   "source": [
    "# drop non-existent images\n",
    "non = []\n",
    "occ_non = []\n",
    "for location in tqdm(annot_df.iloc[:]['Left-Fundus']):\n",
    "    if not os.path.exists(os.path.join(prep_train, location)):\n",
    "        non.append(location)\n",
    "        \n",
    "for location in tqdm(annot_df.iloc[:]['Right-Fundus']):\n",
    "    if not os.path.exists(os.path.join(prep_train, location)):\n",
    "        non.append(location)\n",
    "        \n",
    "for location in tqdm(occ_df.iloc[:]['filename']):\n",
    "    if not os.path.exists(os.path.join(occ_path, location)):\n",
    "        occ_non.append(location)\n",
    "    \n",
    "annot_df = annot_df.loc[(~annot_df['Left-Fundus'].str.match('|'.join(non)))]\n",
    "annot_df = annot_df.loc[(~annot_df['Right-Fundus'].str.match('|'.join(non)))]\n",
    "# occ_df = occ_df.loc[(~occ_df['filename'].str.match('|'.join(occ_non)))]\n",
    "\n",
    "print('odir_df: ', len(annot_df))\n",
    "# print('occ_df: ', len(occ_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLAHE Enhancement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, plot=False, image_size=(256, 256)):\n",
    "  # mask of colored pixels\n",
    "  mask = image > 0\n",
    "\n",
    "  # coordinates of colored pixels\n",
    "  coordinates = np.argwhere(mask)\n",
    "\n",
    "  # binding box of non-black pixels\n",
    "  x0, y0, s0 = coordinates.min(axis=0)\n",
    "  x1, y1, s1 = coordinates.max(axis=0) + 1 # slices are exclusive at the top\n",
    "\n",
    "  # get the contents of the bounding box\n",
    "  cropped = image[x0:x1, y0:y1]\n",
    "\n",
    "  # convert to YUV for equalization\n",
    "  img_yuv = cv2.cvtColor(cropped, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "  # apply adaptive equalization\n",
    "  clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "  img_yuv[:, :, 0] = clahe.apply(img_yuv[:, :, 0])\n",
    "\n",
    "  # apply image normalization\n",
    "  mask = np.zeros((256, 256))\n",
    "  normalized = cv2.normalize(img_yuv[:,:,0], mask, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "  # convert back to rgb\n",
    "  new_image = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "\n",
    "  new_image = cv2.resize(new_image, image_size, interpolation=cv2.INTER_AREA)\n",
    "  cropped_resized = cv2.resize(cropped, image_size, interpolation=cv2.INTER_AREA)\n",
    "  if plot:\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Original - {image.shape}\")\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "\n",
    "    # ----------------- #\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(new_image)\n",
    "    plt.title(f\"Preprocessed - {new_image.shape}\")\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "  \n",
    "  return cropped_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "test_direc = os.path.join(test_folder, 'myopia')\n",
    "test_files = os.listdir(os.path.join(test_folder, \"myopia\"))\n",
    "try:\n",
    "  rand_idx = np.random.randint(0, len(glaucoma_data))\n",
    "  image = cv2.imread(os.path.join(glaucoma_ds, glaucoma_data[rand_idx]))\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  new_image = crop_image(image, plot=True, image_size=(256, 256))\n",
    "except Exception as exc:\n",
    "  traceback.print_tb(exc.__traceback__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess Glaucoma Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glaucoma_prepped = []\n",
    "\n",
    "try:\n",
    "    for img in tqdm(os.listdir(glaucoma_ds)):\n",
    "        img_path = os.path.join(glaucoma_ds, img)\n",
    "        if os.path.isfile(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            new_image = crop_image(image, plot=False, image_size=(IMG_SIZE, IMG_SIZE))\n",
    "            glaucoma_prepped.append(new_image)\n",
    "except Exception as exc:\n",
    "    traceback.print_tb(exc.__traceback__)\n",
    "    \n",
    "print(\"length: \", len(glaucoma_prepped))\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "rand_idx = np.random.randint(0, len(glaucoma_prepped))\n",
    "plt.imshow(glaucoma_prepped[rand_idx])\n",
    "plt.title(\"shape: {0}\".format(glaucoma_prepped[rand_idx].shape))\n",
    "plt.grid(False)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "fCS9WUTy_fT9"
   },
   "source": [
    "# Step 3: Data Mapping\n",
    "* Mapping retinal images to their respective classes (disease)\n",
    "* Start with two classes (Cataract and Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.060663Z",
     "iopub.status.busy": "2022-02-16T15:57:43.060331Z",
     "iopub.status.idle": "2022-02-16T15:57:43.069927Z",
     "shell.execute_reply": "2022-02-16T15:57:43.068978Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.060626Z"
    },
    "id": "JLqIIjkgjwab"
   },
   "outputs": [],
   "source": [
    "# upsample function\n",
    "def upsample_columns(df, max_size):\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    perc = len(df) / max_size\n",
    "    \n",
    "    size = int(max_size - (perc * max_size))\n",
    "    print(\"upsampled by: \", size)\n",
    "    for i in range(size):\n",
    "        rand_idx = np.random.randint(0, len(df))\n",
    "#         eye = df[rand_idx]\n",
    "        eye = df.at[rand_idx, 'Left-Fundus']\n",
    "        row = df.loc[df['Left-Fundus'].str.match(eye)]\n",
    "        \n",
    "        if len(row) > 1:\n",
    "            df = df.append(row.iloc[0], ignore_index=True)\n",
    "        else:\n",
    "            df = df.append(row, ignore_index=True)\n",
    "#         df = pd.concat([df, row]).reset_index(drop=True)\n",
    "#     df = pd.Series(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.071583Z",
     "iopub.status.busy": "2022-02-16T15:57:43.071307Z",
     "iopub.status.idle": "2022-02-16T15:57:43.080131Z",
     "shell.execute_reply": "2022-02-16T15:57:43.079349Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.071538Z"
    },
    "id": "3PYp3nXYjwac",
    "outputId": "4b633262-5b81-4da2-f8db-35e9a514fb12"
   },
   "outputs": [],
   "source": [
    "# eye = df_hypertension.at[322, 'Left-Fundus']\n",
    "# row = df_hypertension.loc[df_hypertension['Left-Fundus'].str.match(eye)]\n",
    "# # conc = pd.concat([df_hypertension, row])\n",
    "# conc = df_hypertension.append(row.iloc[0], ignore_index=True)\n",
    "# # row.iloc[0]\n",
    "# conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.083203Z",
     "iopub.status.busy": "2022-02-16T15:57:43.082541Z",
     "iopub.status.idle": "2022-02-16T15:57:43.088182Z",
     "shell.execute_reply": "2022-02-16T15:57:43.087356Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.08315Z"
    },
    "id": "9O0jUpYkjwad"
   },
   "outputs": [],
   "source": [
    "# print(df_slim.at[432, 'Left-Fundus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.090401Z",
     "iopub.status.busy": "2022-02-16T15:57:43.089781Z",
     "iopub.status.idle": "2022-02-16T15:57:43.11431Z",
     "shell.execute_reply": "2022-02-16T15:57:43.113636Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.09036Z"
    },
    "id": "1dbDE3tXjwae",
    "outputId": "15b5f13b-d945-455a-a6ac-2d5b64e625a8"
   },
   "outputs": [],
   "source": [
    "# slim to necessary columns\n",
    "df_slim = annot_df.iloc[:, 1:15]\n",
    "df_slim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "-KkjeL5OFDvq"
   },
   "source": [
    "### Extract Cataract Images (Left and Right Retinas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.11613Z",
     "iopub.status.busy": "2022-02-16T15:57:43.115656Z",
     "iopub.status.idle": "2022-02-16T15:57:43.140818Z",
     "shell.execute_reply": "2022-02-16T15:57:43.14006Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.116095Z"
    },
    "id": "NZiJsVhljwaj",
    "outputId": "6713050a-295b-46d7-a57a-3507a6db64fc"
   },
   "outputs": [],
   "source": [
    "# extract left cataract images\n",
    "df_left_cat = df_slim[df_slim['Left-Diagnostic Keywords'].str.match('cataract')]\n",
    "df_left_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.142393Z",
     "iopub.status.busy": "2022-02-16T15:57:43.142152Z",
     "iopub.status.idle": "2022-02-16T15:57:43.165271Z",
     "shell.execute_reply": "2022-02-16T15:57:43.164348Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.142361Z"
    },
    "id": "WtD7hRlrjwal",
    "outputId": "d25084a2-1433-4020-e5de-3e0661581013"
   },
   "outputs": [],
   "source": [
    "# extract right cataract images\n",
    "df_right_cat = df_slim[df_slim['Right-Diagnostic Keywords'].str.match('cataract')]\n",
    "df_right_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.166748Z",
     "iopub.status.busy": "2022-02-16T15:57:43.166351Z",
     "iopub.status.idle": "2022-02-16T15:57:43.175546Z",
     "shell.execute_reply": "2022-02-16T15:57:43.174765Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.166712Z"
    },
    "id": "DTFc4PIgId8F",
    "outputId": "49a6fca1-1aa7-4198-d627-c5ebea9ac23e"
   },
   "outputs": [],
   "source": [
    "annot_df.loc[annot_df['D'] == 1, 'Left-Fundus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "A5NcpQoSJ4Wd"
   },
   "source": [
    "### Combine Cataract Left and Right Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.177276Z",
     "iopub.status.busy": "2022-02-16T15:57:43.176892Z",
     "iopub.status.idle": "2022-02-16T15:57:43.198179Z",
     "shell.execute_reply": "2022-02-16T15:57:43.197398Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.177241Z"
    },
    "id": "O25gnq1ojwap",
    "outputId": "38944ddf-e272-4add-e706-56f5c8cc228d"
   },
   "outputs": [],
   "source": [
    "# df_cat_filenames = df_left_cat['Left-Fundus'].append(df_right_cat['Right-Fundus'], ignore_index=True)\n",
    "df_cat_filenames = pd.concat([df_left_cat, df_right_cat])\n",
    "df_cat_filenames.drop(['Patient Age', 'Patient Sex', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'], axis='columns', inplace=True)\n",
    "# df_cat_filenames = df_cat_filenames.sample(n=485).reset_index(drop=True)\n",
    "df_cat_filenames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.201047Z",
     "iopub.status.busy": "2022-02-16T15:57:43.200803Z",
     "iopub.status.idle": "2022-02-16T15:57:43.216099Z",
     "shell.execute_reply": "2022-02-16T15:57:43.215483Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.201014Z"
    },
    "id": "-Co4rWi3KOWv",
    "outputId": "00a9ce5f-911d-4276-fd9b-0b7e53e9374a"
   },
   "outputs": [],
   "source": [
    "df_cat_filenames.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.217692Z",
     "iopub.status.busy": "2022-02-16T15:57:43.21723Z",
     "iopub.status.idle": "2022-02-16T15:57:43.223112Z",
     "shell.execute_reply": "2022-02-16T15:57:43.222346Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.217655Z"
    },
    "id": "XLLhPsQ_KRpX",
    "outputId": "6dc87b97-b4ae-423a-dc3c-4925eb99b83c"
   },
   "outputs": [],
   "source": [
    "len(df_cat_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "h-LbF5DxPxmm"
   },
   "source": [
    "### Extract Normal Retinal Images (Left and Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.225133Z",
     "iopub.status.busy": "2022-02-16T15:57:43.224394Z",
     "iopub.status.idle": "2022-02-16T15:57:43.248996Z",
     "shell.execute_reply": "2022-02-16T15:57:43.2482Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.225094Z"
    },
    "id": "dCohAHAsN0-_",
    "outputId": "d928636f-4c3b-4ab7-bafd-848353047673"
   },
   "outputs": [],
   "source": [
    "# extract left norms\n",
    "df_left_norm = df_slim.loc[df_slim['Left-Diagnostic Keywords'].str.match('normal')]\n",
    "df_left_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.250547Z",
     "iopub.status.busy": "2022-02-16T15:57:43.250237Z",
     "iopub.status.idle": "2022-02-16T15:57:43.273924Z",
     "shell.execute_reply": "2022-02-16T15:57:43.273274Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.250514Z"
    },
    "id": "mwp-EfIjQK1D",
    "outputId": "7cc42c2c-d66d-4a67-cb3f-16b5d362c1a5"
   },
   "outputs": [],
   "source": [
    "# extract right norm\n",
    "df_right_norm = df_slim.loc[df_slim['Right-Diagnostic Keywords'].str.match('normal')]\n",
    "df_right_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "IsUfnz0_QYFK"
   },
   "source": [
    "### Combine Normal Images (Left and Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.275538Z",
     "iopub.status.busy": "2022-02-16T15:57:43.27486Z",
     "iopub.status.idle": "2022-02-16T15:57:43.295623Z",
     "shell.execute_reply": "2022-02-16T15:57:43.294994Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.275502Z"
    },
    "id": "DiLpKDC6jwa2",
    "outputId": "5a911884-49c1-4026-ebf9-54fee5439719"
   },
   "outputs": [],
   "source": [
    "# df_norm_filenames = df_left_norm['Left-Fundus'].append(df_right_norm['Right-Fundus'], ignore_index=True)\n",
    "df_norm_filenames = pd.concat([df_left_norm, df_right_norm])\n",
    "df_norm_filenames.drop(['Patient Age', 'Patient Sex', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'], axis='columns', inplace=True)\n",
    "df_norm_filenames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.296849Z",
     "iopub.status.busy": "2022-02-16T15:57:43.296537Z",
     "iopub.status.idle": "2022-02-16T15:57:43.309455Z",
     "shell.execute_reply": "2022-02-16T15:57:43.308568Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.296815Z"
    },
    "id": "XEzJMOrGQi8W",
    "outputId": "22b1f4f8-20c6-422c-c8a2-ff2ea63048df"
   },
   "outputs": [],
   "source": [
    "df_norm_filenames.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.3116Z",
     "iopub.status.busy": "2022-02-16T15:57:43.311109Z",
     "iopub.status.idle": "2022-02-16T15:57:43.317817Z",
     "shell.execute_reply": "2022-02-16T15:57:43.31707Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.311525Z"
    },
    "id": "OinMd0BvQlGq",
    "outputId": "1ff5d97b-3008-48e0-eb2f-2d78ed5d64f3"
   },
   "outputs": [],
   "source": [
    "len(df_norm_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.319873Z",
     "iopub.status.busy": "2022-02-16T15:57:43.319034Z",
     "iopub.status.idle": "2022-02-16T15:57:43.348244Z",
     "shell.execute_reply": "2022-02-16T15:57:43.347481Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.319836Z"
    },
    "id": "I5oSvKv5jwa6",
    "outputId": "055f7075-2d6a-4bd8-bcc3-5b7db1f0392b"
   },
   "outputs": [],
   "source": [
    "# extract diabetes\n",
    "df_left_diabetes = df_slim.loc[(df_slim['Left-Diagnostic Keywords'].str.contains('|'.join(['diabetic', 'proliferative'])))]\n",
    "df_right_diabetes = df_slim.loc[(df_slim['Right-Diagnostic Keywords'].str.contains('|'.join(['diabetic', 'proliferative'])))]\n",
    "\n",
    "# combine diabetes\n",
    "# df_diabetes = df_left_diabetes['Left-Fundus'].append(df_right_diabetes['Right-Fundus'], ignore_index=True)\n",
    "df_diabetes = pd.concat([df_left_diabetes, df_right_diabetes])\n",
    "df_diabetes.drop(['Patient Age', 'Patient Sex', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'], axis='columns', inplace=True)\n",
    "print(\"diabetes: \", len(df_diabetes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.349833Z",
     "iopub.status.busy": "2022-02-16T15:57:43.349594Z",
     "iopub.status.idle": "2022-02-16T15:57:43.368741Z",
     "shell.execute_reply": "2022-02-16T15:57:43.367758Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.349801Z"
    },
    "id": "pwGjxROKjwa7",
    "outputId": "29ecd8a9-2eac-4cc0-bee9-be442dbb5eb8"
   },
   "outputs": [],
   "source": [
    "# extract glaucoma\n",
    "df_left_glaucoma = df_slim.loc[(df_slim['Left-Diagnostic Keywords'].str.contains('glaucoma'))]\n",
    "df_right_glaucoma = df_slim.loc[(df_slim['Right-Diagnostic Keywords'].str.contains('glaucoma'))]\n",
    "\n",
    "# combine glaucoma\n",
    "# df_glaucoma = df_left_glaucoma.append(df_right_glaucoma, ignore_index=True)\n",
    "df_glaucoma = pd.concat([df_left_glaucoma, df_right_glaucoma])\n",
    "df_glaucoma.drop(['Patient Age', 'Patient Sex', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'], axis='columns', inplace=True)\n",
    "df_glaucoma = upsample_columns(df_glaucoma, len(df_cat_filenames))\n",
    "print(\"glaucoma: \", len(df_glaucoma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.371232Z",
     "iopub.status.busy": "2022-02-16T15:57:43.370297Z",
     "iopub.status.idle": "2022-02-16T15:57:43.391224Z",
     "shell.execute_reply": "2022-02-16T15:57:43.390443Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.371194Z"
    },
    "id": "9W5ox6Iijwa8",
    "outputId": "ccb1ea42-11db-4451-9c4f-3f224f665f9b"
   },
   "outputs": [],
   "source": [
    "# extract amd\n",
    "df_left_amd = df_slim.loc[(df_slim['Left-Diagnostic Keywords'].str.contains('age-related'))]\n",
    "df_right_amd = df_slim.loc[(df_slim['Right-Diagnostic Keywords'].str.contains('age-related'))]\n",
    "\n",
    "# combine amd\n",
    "# df_amd = df_left_amd['Left-Fundus'].append(df_right_amd['Right-Fundus'], ignore_index=True)\n",
    "df_amd = pd.concat([df_left_amd, df_right_amd])\n",
    "df_amd.drop(['Patient Age', 'Patient Sex', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'],axis='columns', inplace=True)\n",
    "df_amd = upsample_columns(df_amd, len(df_cat_filenames))\n",
    "print(\"amd: \", len(df_amd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.393349Z",
     "iopub.status.busy": "2022-02-16T15:57:43.393043Z",
     "iopub.status.idle": "2022-02-16T15:57:43.760421Z",
     "shell.execute_reply": "2022-02-16T15:57:43.759612Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.393313Z"
    },
    "id": "q-lePMqOjwa_",
    "outputId": "697686d4-cdb9-4ca0-9113-02e1cf2f7180"
   },
   "outputs": [],
   "source": [
    "# extract hypertension\n",
    "df_left_hypertension = df_slim.loc[(df_slim['Left-Diagnostic Keywords'].str.contains('hypertensive'))]\n",
    "df_right_hypertension = df_slim.loc[(df_slim['Right-Diagnostic Keywords'].str.contains('hypertensive'))]\n",
    "\n",
    "# combine hypertension \n",
    "# df_hypertension = df_left_hypertension['Left-Fundus'].append(df_right_hypertension['Right-Fundus'], ignore_index=True)\n",
    "df_hypertension = pd.concat([df_left_hypertension,df_right_hypertension]).reset_index(drop=True)\n",
    "df_hypertension.drop(['Patient Age', 'Patient Sex', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'], axis='columns', inplace=True)\n",
    "df_hypertension = upsample_columns(df_hypertension, len(df_cat_filenames))\n",
    "print(\"hypertension: \", len(df_hypertension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:43.762214Z",
     "iopub.status.busy": "2022-02-16T15:57:43.761951Z",
     "iopub.status.idle": "2022-02-16T15:57:44.006495Z",
     "shell.execute_reply": "2022-02-16T15:57:44.005808Z",
     "shell.execute_reply.started": "2022-02-16T15:57:43.762178Z"
    },
    "id": "nOAZzBfSjwbA",
    "outputId": "c360b69b-0c45-499b-a739-4a33589cfd77"
   },
   "outputs": [],
   "source": [
    "# extract myopia\n",
    "df_left_myopia = df_slim.loc[(df_slim['Left-Diagnostic Keywords'].str.contains('pathological myopia'))]\n",
    "df_right_myopia = df_slim.loc[(df_slim['Right-Diagnostic Keywords'].str.contains('pathological myopia'))]\n",
    "\n",
    "# combine myopia\n",
    "# df_myopia = df_left_myopia['Left-Fundus'].append(df_right_myopia['Right-Fundus'], ignore_index=True)\n",
    "df_myopia = pd.concat([df_left_myopia, df_right_myopia])\n",
    "df_myopia.drop(['Patient Age', 'Patient Sex', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'], axis='columns', inplace=True)\n",
    "df_myopia = upsample_columns(df_myopia,len(df_cat_filenames))\n",
    "# df_myopia = upsample_columns(df_myopia,970)\n",
    "print(\"myopia: \", len(df_myopia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:44.007883Z",
     "iopub.status.busy": "2022-02-16T15:57:44.007519Z",
     "iopub.status.idle": "2022-02-16T15:57:44.033364Z",
     "shell.execute_reply": "2022-02-16T15:57:44.032589Z",
     "shell.execute_reply.started": "2022-02-16T15:57:44.007847Z"
    },
    "id": "HrP-sx3hjwbB",
    "outputId": "fbfccf28-5cbd-42be-f15b-054b707b1312"
   },
   "outputs": [],
   "source": [
    "common_diseases = ['myopia', 'normal fundus', 'cataract', 'glaucoma', \\\n",
    "                   'hypertensive', 'proliferative', 'age-related', 'diabetic']\n",
    "df_left_others = df_slim.loc[(~df_slim['Left-Diagnostic Keywords'].str.contains('|'.join(common_diseases)))]\n",
    "df_right_others = df_slim.loc[(~df_slim['Right-Diagnostic Keywords'].str.contains('|'.join(common_diseases)))]\n",
    "\n",
    "# combine others\n",
    "# df_others = df_left_others['Left-Fundus'].append(df_right_others['Right-Fundus'], ignore_index=True)\n",
    "df_others = pd.concat([df_left_others, df_right_others])\n",
    "df_others.drop(['Patient Age', 'Patient Sex', 'Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'], axis='columns', inplace=True)\n",
    "df_others = upsample_columns(df_others, len(df_cat_filenames))\n",
    "print(\"others: \", len(df_others))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "INhIGwCHQqx7"
   },
   "source": [
    "### Select and Create a Random Sample\n",
    "* we need to minimize the normal data to match the number of cataract samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:44.035299Z",
     "iopub.status.busy": "2022-02-16T15:57:44.03467Z",
     "iopub.status.idle": "2022-02-16T15:57:44.052824Z",
     "shell.execute_reply": "2022-02-16T15:57:44.052147Z",
     "shell.execute_reply.started": "2022-02-16T15:57:44.035261Z"
    },
    "id": "LEB4WG3ejwbG",
    "outputId": "7f6f630a-e5b3-4baa-e561-1b04d7b5eab3"
   },
   "outputs": [],
   "source": [
    "# There are 572 cataract images\n",
    "df_norm_filenames_random = df_norm_filenames.sample(n=485)\n",
    "df_norm_filenames_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:44.054347Z",
     "iopub.status.busy": "2022-02-16T15:57:44.054101Z",
     "iopub.status.idle": "2022-02-16T15:57:44.073008Z",
     "shell.execute_reply": "2022-02-16T15:57:44.072364Z",
     "shell.execute_reply.started": "2022-02-16T15:57:44.054314Z"
    },
    "id": "N25DRwNKQ44T",
    "outputId": "e50aa1b2-e690-41a5-ccb5-0c6caf0615e3"
   },
   "outputs": [],
   "source": [
    "df_norm_filenames_random = df_norm_filenames_random.reset_index(drop=True)\n",
    "df_norm_filenames_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:44.074669Z",
     "iopub.status.busy": "2022-02-16T15:57:44.073999Z",
     "iopub.status.idle": "2022-02-16T15:57:44.084506Z",
     "shell.execute_reply": "2022-02-16T15:57:44.083715Z",
     "shell.execute_reply.started": "2022-02-16T15:57:44.074633Z"
    },
    "id": "6DETYn8HjwbK"
   },
   "outputs": [],
   "source": [
    "##### df_normal_dn = df_normal.sample(n=381).reset_index(drop=True)\n",
    "df_diabetes_dn = df_diabetes.sample(n=485).reset_index(drop=True)\n",
    "df_others_dn = df_others.sample(n=485).reset_index(drop=True)\n",
    "df_myopia_dn = df_myopia.sample(n=485).reset_index(drop=True)\n",
    "df_amd_dn = df_amd.sample(n=485).reset_index(drop=True)\n",
    "df_glaucoma_dn = df_glaucoma.sample(n=485).reset_index(drop=True)\n",
    "# df_cataract_dn = df_cataract.sample(n=381).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:44.086862Z",
     "iopub.status.busy": "2022-02-16T15:57:44.086093Z",
     "iopub.status.idle": "2022-02-16T15:57:44.091215Z",
     "shell.execute_reply": "2022-02-16T15:57:44.090436Z",
     "shell.execute_reply.started": "2022-02-16T15:57:44.086826Z"
    }
   },
   "outputs": [],
   "source": [
    "# # df_normal_dn = df_normal.sample(n=381).reset_index(drop=True)\n",
    "# df_diabetes_dn = df_diabetes.sample(n=458).reset_index(drop=True)\n",
    "# df_others_dn = df_others.sample(n=489).reset_index(drop=True)\n",
    "# df_myopia_dn = df_myopia.sample(n=478).reset_index(drop=True)\n",
    "# df_amd_dn = df_amd.sample(n=469).reset_index(drop=True)\n",
    "# df_glaucoma_dn = df_glaucoma.sample(n=494).reset_index(drop=True)\n",
    "# # df_cataract_dn = df_cataract.sample(n=381).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:44.093232Z",
     "iopub.status.busy": "2022-02-16T15:57:44.092357Z",
     "iopub.status.idle": "2022-02-16T15:57:44.101905Z",
     "shell.execute_reply": "2022-02-16T15:57:44.101186Z",
     "shell.execute_reply.started": "2022-02-16T15:57:44.093138Z"
    }
   },
   "outputs": [],
   "source": [
    "df_glaucoma_dn.iloc[1, 0] # [row, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:44.107702Z",
     "iopub.status.busy": "2022-02-16T15:57:44.106208Z",
     "iopub.status.idle": "2022-02-16T15:57:44.113799Z",
     "shell.execute_reply": "2022-02-16T15:57:44.11283Z",
     "shell.execute_reply.started": "2022-02-16T15:57:44.107666Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.randint(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:44.115967Z",
     "iopub.status.busy": "2022-02-16T15:57:44.115401Z",
     "iopub.status.idle": "2022-02-16T15:57:45.33919Z",
     "shell.execute_reply": "2022-02-16T15:57:45.338547Z",
     "shell.execute_reply.started": "2022-02-16T15:57:44.11593Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "for i in range(9):\n",
    "    rand_idx = np.random.randint(0, len(df_myopia_dn))\n",
    "    img_file = df_myopia_dn.iloc[rand_idx, np.random.randint(0, 2)]\n",
    "    img = cv2.imread(os.path.join(prep_train, img_file))\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.title(f\"{img_file.split('.')[0]}: myopia\")\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:45.340991Z",
     "iopub.status.busy": "2022-02-16T15:57:45.340229Z",
     "iopub.status.idle": "2022-02-16T15:57:45.352092Z",
     "shell.execute_reply": "2022-02-16T15:57:45.351361Z",
     "shell.execute_reply.started": "2022-02-16T15:57:45.340952Z"
    }
   },
   "outputs": [],
   "source": [
    "dframe_fundus = pd.concat([df_norm_filenames_random, df_cat_filenames, df_glaucoma_dn, df_myopia_dn])\n",
    "dframe_fundus.iloc[:, 2:10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:45.353616Z",
     "iopub.status.busy": "2022-02-16T15:57:45.353198Z",
     "iopub.status.idle": "2022-02-16T15:57:45.359113Z",
     "shell.execute_reply": "2022-02-16T15:57:45.358569Z",
     "shell.execute_reply.started": "2022-02-16T15:57:45.353583Z"
    },
    "id": "DQpb2Ss8jwbL"
   },
   "outputs": [],
   "source": [
    "# count labels\n",
    "def extract_labels(df, initial):\n",
    "    labels = []\n",
    "    fundus_names = df.iloc[:]\n",
    "    \n",
    "    for i in range(len(fundus_names)):\n",
    "        labels.append(initial)\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYr-lgvSjwbc"
   },
   "source": [
    "## Visualize Class Distribution (After data mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:45.362532Z",
     "iopub.status.busy": "2022-02-16T15:57:45.362005Z",
     "iopub.status.idle": "2022-02-16T15:57:45.378244Z",
     "shell.execute_reply": "2022-02-16T15:57:45.377393Z",
     "shell.execute_reply.started": "2022-02-16T15:57:45.362496Z"
    },
    "id": "u1u14Fiqjwbd",
    "outputId": "ac002ac7-1d71-421c-92ec-ea951a282253"
   },
   "outputs": [],
   "source": [
    "total_count_labels = []\n",
    "labels_each_count = []\n",
    "\n",
    "labels_normal = extract_labels(df_norm_filenames_random, \"N\")\n",
    "labels_diabetes = extract_labels(df_diabetes_dn, \"D\")\n",
    "labels_glaucoma = extract_labels(df_glaucoma_dn, \"G\")\n",
    "labels_cataract = extract_labels(df_cat_filenames, \"C\")\n",
    "labels_amd = extract_labels(df_amd_dn, \"A\")\n",
    "labels_hypertension = extract_labels(df_hypertension, \"H\")\n",
    "labels_myopia = extract_labels(df_myopia_dn, \"M\")\n",
    "labels_others = extract_labels(df_others_dn, \"O\")\n",
    "\n",
    "total_count_labels += labels_normal\n",
    "# total_count_labels += labels_diabetes\n",
    "total_count_labels += labels_glaucoma\n",
    "total_count_labels += labels_cataract\n",
    "# total_count_labels += labels_amd\n",
    "# total_count_labels += labels_hypertension\n",
    "total_count_labels += labels_myopia\n",
    "# total_count_labels += labels_others\n",
    "\n",
    "labels_each_count.append(len(labels_normal))\n",
    "# labels_each_count.append(len(labels_diabetes))\n",
    "labels_each_count.append(len(labels_glaucoma))\n",
    "labels_each_count.append(len(labels_cataract))\n",
    "# labels_each_count.append(len(labels_amd))\n",
    "# labels_each_count.append(len(labels_hypertension))\n",
    "labels_each_count.append(len(labels_myopia))\n",
    "# labels_each_count.append(len(labels_others))\n",
    "\n",
    "print(\"Total Count: \", len(total_count_labels))\n",
    "labels_each_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:46.196419Z",
     "iopub.status.busy": "2022-02-16T15:57:46.196172Z",
     "iopub.status.idle": "2022-02-16T15:57:46.20423Z",
     "shell.execute_reply": "2022-02-16T15:57:46.202169Z",
     "shell.execute_reply.started": "2022-02-16T15:57:46.19639Z"
    }
   },
   "outputs": [],
   "source": [
    "total_count_labels += occ_total_count\n",
    "labels_each_count = [(l1+l2) for l1, l2 in zip(labels_each_count, occ_labels_count)]\n",
    "print(labels_each_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:47.111474Z",
     "iopub.status.busy": "2022-02-16T15:57:47.110858Z",
     "iopub.status.idle": "2022-02-16T15:57:47.213873Z",
     "shell.execute_reply": "2022-02-16T15:57:47.213157Z",
     "shell.execute_reply.started": "2022-02-16T15:57:47.111421Z"
    },
    "id": "STncTZJ7jwbf",
    "outputId": "a165b300-9a36-4108-a098-794ec1a9b4aa"
   },
   "outputs": [],
   "source": [
    "init_notebook_mode(connected=False)\n",
    "configure_plotly_browser_state()\n",
    "\n",
    "labels_ser = pd.Series(total_count_labels, name='label')\n",
    "labels_df = pd.DataFrame({\n",
    "    'labels': labels_ser.value_counts().index,\n",
    "    'count': labels_ser.value_counts()\n",
    "})\n",
    "\n",
    "labels_count = sorted(labels_each_count, reverse=True)\n",
    "labels_df['percentage'] = [float(i / sum(labels_count)) for i in labels_count]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "fig = go.Figure(data=[go.Bar(\n",
    "                x=labels_df['labels'],\n",
    "                y=labels_df['count'],\n",
    "                text=labels_df['percentage'].apply(lambda x: \"{0:1.2f}%\".format(x * 100)),\n",
    "                textposition='auto',\n",
    "                marker=dict(\n",
    "                    colorscale='Viridis'\n",
    "                )\n",
    "                )])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Resampled Fundus Image Distribution',\n",
    "    xaxis_title='disease',\n",
    "    yaxis_title='count',\n",
    "    font=dict(\n",
    "        size=13\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNt31vV4jwb-"
   },
   "source": [
    "#### Split Data (After resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:47.627593Z",
     "iopub.status.busy": "2022-02-16T15:57:47.626847Z",
     "iopub.status.idle": "2022-02-16T15:57:47.631189Z",
     "shell.execute_reply": "2022-02-16T15:57:47.630457Z",
     "shell.execute_reply.started": "2022-02-16T15:57:47.627548Z"
    },
    "id": "HVfK8OqQo5mI"
   },
   "outputs": [],
   "source": [
    "# check for non-existent\n",
    "\n",
    "# not_exists = []\n",
    "\n",
    "# for file in tqdm(dframe_fundus.iloc[:]['Left-Fundus']):\n",
    "#   if not os.path.exists(os.path.join(prep_train, file)):\n",
    "#     not_exists.append(file)\n",
    "\n",
    "# for file in tqdm(dframe_fundus.iloc[:]['Right-Fundus']):\n",
    "#   if not os.path.exists(os.path.join(prep_train, file)):\n",
    "#     not_exists.append(file)\n",
    "\n",
    "# dframe_fundus = dframe_fundus.loc[(~dframe_fundus['Left-Fundus'].str.match('|'.join(not_exists)))]\n",
    "# dframe_fundus = dframe_fundus.loc[(~dframe_fundus['Right-Fundus'].str.match('|'.join(not_exists)))]\n",
    "\n",
    "# len(dframe_fundus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:48.746737Z",
     "iopub.status.busy": "2022-02-16T15:57:48.746083Z",
     "iopub.status.idle": "2022-02-16T15:57:48.758126Z",
     "shell.execute_reply": "2022-02-16T15:57:48.757303Z",
     "shell.execute_reply.started": "2022-02-16T15:57:48.746697Z"
    }
   },
   "outputs": [],
   "source": [
    "dframe_fundus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:49.031097Z",
     "iopub.status.busy": "2022-02-16T15:57:49.030667Z",
     "iopub.status.idle": "2022-02-16T15:57:49.039792Z",
     "shell.execute_reply": "2022-02-16T15:57:49.038378Z",
     "shell.execute_reply.started": "2022-02-16T15:57:49.031069Z"
    }
   },
   "outputs": [],
   "source": [
    "dframe_fundus.iloc[:, 2:10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:50.60178Z",
     "iopub.status.busy": "2022-02-16T15:57:50.601518Z",
     "iopub.status.idle": "2022-02-16T15:57:54.184372Z",
     "shell.execute_reply": "2022-02-16T15:57:54.183524Z",
     "shell.execute_reply.started": "2022-02-16T15:57:50.601752Z"
    },
    "id": "X-Szdma6jwb_",
    "outputId": "47f4574a-83f3-441f-e98b-b7394a9724e7"
   },
   "outputs": [],
   "source": [
    "left = []\n",
    "right = []\n",
    "occ_files = []\n",
    "\n",
    "# dframe_fundus = pd.concat([df_norm_filenames_random, df_cat_filenames, df_diabetes_dn,\n",
    "#                           df_glaucoma_dn, df_myopia_dn, df_hypertension, df_amd_dn,\n",
    "#                           df_others_dn]).reset_index(drop=True)\n",
    "\n",
    "dframe_fundus = pd.concat([df_norm_filenames_random, df_cat_filenames, df_glaucoma_dn, df_myopia_dn])\n",
    "\n",
    "dframe_fundus = dframe_fundus.sample(frac=1).reset_index(drop=True)\n",
    "occ_dframe = occ_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# dframe_fundus = dframe_fundus.sample(n=2600).reset_index(drop=True)\n",
    "# dframe_fundus.tail(5)\n",
    "\n",
    "# check if all filenames exist\n",
    "\n",
    "\n",
    "for file in tqdm(dframe_fundus.iloc[:]['Left-Fundus']):\n",
    "    if os.path.isfile(os.path.join(prep_train, file)):\n",
    "#         img = cv2.imread(os.path.join(prep_train, file), cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.imread(os.path.join(prep_train, file), 0)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "        left.append(img)\n",
    "        \n",
    "for file in tqdm(dframe_fundus.iloc[:]['Right-Fundus']):\n",
    "    if os.path.isfile(os.path.join(prep_train, file)):\n",
    "        img = cv2.imread(os.path.join(prep_train, file), 0)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "        right.append(img)\n",
    "        \n",
    "for file in tqdm(occ_dframe.iloc[:]['filename']):\n",
    "    if os.path.isfile(os.path.join(occ_path, file)):\n",
    "        img = cv2.imread(os.path.join(occ_path, file), 0)\n",
    "        img = img.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "        occ_files.append(img)\n",
    "\n",
    "X0 = np.array(occ_files)\n",
    "X1 = np.array(left)\n",
    "X2 = np.array(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:54.186322Z",
     "iopub.status.busy": "2022-02-16T15:57:54.18598Z",
     "iopub.status.idle": "2022-02-16T15:57:54.191976Z",
     "shell.execute_reply": "2022-02-16T15:57:54.19121Z",
     "shell.execute_reply.started": "2022-02-16T15:57:54.186282Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X0.shape, X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:57:54.194178Z",
     "iopub.status.busy": "2022-02-16T15:57:54.193346Z",
     "iopub.status.idle": "2022-02-16T15:58:01.88733Z",
     "shell.execute_reply": "2022-02-16T15:58:01.886364Z",
     "shell.execute_reply.started": "2022-02-16T15:57:54.194142Z"
    }
   },
   "outputs": [],
   "source": [
    "# RGB\n",
    "\n",
    "left1 = []\n",
    "right1 = []\n",
    "occ_files1 = []\n",
    "for file in tqdm(dframe_fundus.iloc[:]['Left-Fundus']):\n",
    "    if os.path.isfile(os.path.join(prep_train, file)):\n",
    "        img = cv2.imread(os.path.join(prep_train, file), cv2.IMREAD_UNCHANGED)\n",
    "#         img = cv2.imread(os.path.join(prep_train, file), 0)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.reshape(IMG_SIZE, IMG_SIZE, 3)\n",
    "        left1.append(img)\n",
    "        \n",
    "for file in tqdm(dframe_fundus.iloc[:]['Right-Fundus']):\n",
    "    if os.path.isfile(os.path.join(prep_train, file)):\n",
    "        img = cv2.imread(os.path.join(prep_train, file), cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.reshape(IMG_SIZE, IMG_SIZE, 3)\n",
    "        right1.append(img)\n",
    "        \n",
    "for file in tqdm(occ_dframe.iloc[:]['filename']):\n",
    "    if os.path.isfile(os.path.join(occ_path, file)):\n",
    "        img = cv2.imread(os.path.join(occ_path, file), cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.reshape(IMG_SIZE, IMG_SIZE, 3)\n",
    "        occ_files1.append(img)\n",
    "    \n",
    "X3 = np.array(left1)\n",
    "X4 = np.array(right1)\n",
    "X5 = np.array(occ_files1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:58:01.889818Z",
     "iopub.status.busy": "2022-02-16T15:58:01.889272Z",
     "iopub.status.idle": "2022-02-16T15:58:01.902814Z",
     "shell.execute_reply": "2022-02-16T15:58:01.901728Z",
     "shell.execute_reply.started": "2022-02-16T15:58:01.889779Z"
    },
    "id": "7DY4Ya95jwcA",
    "outputId": "96735d3a-61b0-4250-e27a-d37954f327b7"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "classes = list(dframe_fundus.iloc[:, 2:11].sum().index)\n",
    "# y = np.array(dframe_fundus.iloc[:][classes])\n",
    "y = np.array(dframe_fundus.iloc[:][['N', 'C', 'G', 'M']])\n",
    "y = np.array(y)\n",
    "y1 = np.array(occ_dframe.iloc[:][['N', 'C', 'G', 'M']])\n",
    "y = np.concatenate((y, y, y1))\n",
    "print(\"Labels: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYGaqZ7-jwcB"
   },
   "source": [
    "**Train Test Splitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhw3Quw1vKae"
   },
   "source": [
    "**Singular Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:58:01.908557Z",
     "iopub.status.busy": "2022-02-16T15:58:01.908221Z",
     "iopub.status.idle": "2022-02-16T15:58:06.15892Z",
     "shell.execute_reply": "2022-02-16T15:58:06.158121Z",
     "shell.execute_reply.started": "2022-02-16T15:58:01.908444Z"
    },
    "id": "Ny8qbvpmvMU4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.concatenate((X1, X2, X0))\n",
    "# X_norm = X / 255\n",
    "\n",
    "x_train, x_test, \\\n",
    "y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "x_train, x_valid, \\\n",
    "y_train, y_valid = train_test_split(x_train, y_train, test_size=0.10)\n",
    "\n",
    "X_RGB = np.concatenate((X3, X4, X5))\n",
    "# X_norm = X / 255\n",
    "\n",
    "x_train1, x_test1, \\\n",
    "y_train1, y_test1 = train_test_split(X_RGB, y, test_size=0.20)\n",
    "\n",
    "x_train1, x_valid1, \\\n",
    "y_train1, y_valid1 = train_test_split(x_train1, y_train1, test_size=0.10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "n4LwQcE6fs7e"
   },
   "source": [
    "# Step 5: Build Network Architecture (Toy ResNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bf7fLKEPm2SB"
   },
   "source": [
    "#### BatchNorm CReLU ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:03:52.350439Z",
     "iopub.status.busy": "2022-02-16T16:03:52.350179Z",
     "iopub.status.idle": "2022-02-16T16:03:56.359754Z",
     "shell.execute_reply": "2022-02-16T16:03:56.359013Z",
     "shell.execute_reply.started": "2022-02-16T16:03:52.350409Z"
    },
    "id": "kRtz4wfpmbPq",
    "outputId": "ad045ff3-fbf2-4969-f4db-ce64e2ed4e0b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='img')\n",
    "x = layers.Conv2D(32, 3, dtype='float32')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.relu)(x)\n",
    "x = layers.Conv2D(64, 3)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.relu)(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same')(block_1_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "activation_1 = layers.Activation(tf.nn.relu)(block_2_output)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same')(activation_1)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_3_output = layers.add([x, activation_1])\n",
    "activation_2 = layers.Activation(tf.nn.relu)(block_3_output)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same')(activation_2)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_4_output = layers.add([x, activation_2])\n",
    "activation_3 = layers.Activation(tf.nn.relu)(block_4_output)\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same')(activation_3)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.relu)(x)\n",
    "x = layers.Conv2D(96, 3)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.relu)(x)\n",
    "x = layers.Conv2D(128, 3)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.relu)(x)\n",
    "block_5_output = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(128, 3, padding='same')(block_5_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_6_output = layers.add([x, block_5_output])\n",
    "activation_4 = layers.Activation(tf.nn.relu)(block_6_output)\n",
    "\n",
    "x = layers.Conv2D(128, 3, padding='same')(activation_4)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_7_output = layers.add([x, activation_4])\n",
    "activation_5 = layers.Activation(tf.nn.relu)(block_7_output)\n",
    "\n",
    "x = layers.Conv2D(128, 3, padding='same')(activation_5)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(128, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_8_output = layers.add([x, activation_5])\n",
    "activation_6 = layers.Activation(tf.nn.relu)(block_8_output)\n",
    "\n",
    "x = layers.Conv2D(128, 3, padding='same')(activation_6)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.relu)(x)\n",
    "x = layers.Conv2D(192, 3)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.relu)(x)\n",
    "x = layers.Conv2D(256, 3)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.relu)(x)\n",
    "block_9_output = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 3, padding='same')(block_9_output)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_10_output = layers.add([x, block_9_output])\n",
    "activation_7 = layers.Activation(tf.nn.relu)(block_10_output)\n",
    "\n",
    "x = layers.Conv2D(256, 3, padding='same')(activation_7)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_11_output = layers.add([x, block_10_output])\n",
    "activation_8 = layers.Activation(tf.nn.relu)(block_11_output)\n",
    "\n",
    "x = layers.Conv2D(256, 3, padding='same')(activation_8)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(256, 3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "block_12_output = layers.add([x, block_11_output])\n",
    "activation_9 = layers.Activation(tf.nn.relu)(block_12_output)\n",
    "\n",
    "x = layers.Conv2D(256, 3)(activation_9)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(256, 3)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(tf.nn.crelu)(x)\n",
    "x = layers.Conv2D(256, 3, activation=tf.nn.relu, name='conv2d_end')(x)\n",
    "x = layers.GlobalAveragePooling2D(name='global_average_pooling2d')(x)\n",
    "x = layers.Dense(256, activation=tf.nn.relu)(x)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(4, activation=tf.nn.softmax, name='dense_output')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='resnet_batch-norm_crelu')\n",
    "# model.summary()\n",
    "print(\"Layers: \", len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "kw6N4b0iimJd"
   },
   "source": [
    "### Plot Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-11T03:00:09.079763Z",
     "iopub.status.busy": "2022-02-11T03:00:09.0795Z",
     "iopub.status.idle": "2022-02-11T03:00:09.083283Z",
     "shell.execute_reply": "2022-02-11T03:00:09.082608Z",
     "shell.execute_reply.started": "2022-02-11T03:00:09.079734Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# custom_objects = {\"custom_activation\": tf.nn.crelu}\n",
    "# # model = load_model(os.path.join(model_path, \"odir_checkpoint.h5\"), custom_objects=custom_objects)\n",
    "# # model1 = load_model(os.path.join(model_path, \"odir_model-{0:.2f}\".format(test_acc)))\n",
    "# model = load_model(odir_model_merged)\n",
    "# # model1.load_weights(model_path, \"odir_model-{0:.2f}-bw\".format(test_acc))\n",
    "# # model = load_model(odir_model_dir)\n",
    "\n",
    "# # model = tf.saved_model.load(model_path)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-16T16:05:22.356981Z",
     "iopub.status.busy": "2022-02-16T16:05:22.356704Z",
     "iopub.status.idle": "2022-02-16T16:05:30.279982Z",
     "shell.execute_reply": "2022-02-16T16:05:30.278252Z",
     "shell.execute_reply.started": "2022-02-16T16:05:22.356953Z"
    },
    "id": "G8hibZJtiFa5",
    "outputId": "85b937b7-b58a-4d39-d177-1f1e4cebe16b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "model_path = \"trained_models/odir\"\n",
    "if os.path.isdir(model_path):\n",
    "  clear_content(model_path)\n",
    "else:\n",
    "  os.makedirs(model_path)\n",
    "\n",
    "model_diagram_path = os.path.join(model_path, \"odir_model.png\")\n",
    "\n",
    "plot_model(model, model_diagram_path,\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True)\n",
    "\n",
    "# show the plot\n",
    "img = mpimg.imread(model_diagram_path)\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:05:44.556069Z",
     "iopub.status.busy": "2022-02-16T16:05:44.555784Z",
     "iopub.status.idle": "2022-02-16T16:05:44.564276Z",
     "shell.execute_reply": "2022-02-16T16:05:44.563557Z",
     "shell.execute_reply.started": "2022-02-16T16:05:44.55604Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "  \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "\n",
    "    Variables:\n",
    "      weights: numpy array of shape(C,) where C is the number of classes\n",
    "      \n",
    "    Usage:\n",
    "      weights = np.array([0.5, 2, 10]) # Class one at 0.5, 2 is twice the normal weights,\n",
    "                                        10 is 10x\n",
    "      loss = weighted_categorical_crossentropy(weights)\n",
    "      model.compile(loss=loss, optimizer='adam')\n",
    "\n",
    "    Returns:\n",
    "      loss: weighted loss of categorical data\n",
    "    \"\"\"\n",
    "\n",
    "  weights = K.variable(weights)\n",
    "  def loss(y_true, y_pred):\n",
    "    # scale predictions so that the class probas of each sample sum to 1\n",
    "    y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "\n",
    "    # clip to prevents NaN's and Inf's\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "\n",
    "    # calc\n",
    "    y_true = y_true.astype('float64')\n",
    "#     print(y_true, K.log(y_pred))\n",
    "#     print(y_train.dtype, y_pred.dtype)\n",
    "    print(tf.math.round(K.log(y_pred)).dtype)\n",
    "    \n",
    "    loss = y_true * tf.math.round(K.log(y_pred)) * weights\n",
    "#     loss = y_true * K.log(y_pred) * weights\n",
    "    loss = -K.sum(loss, -1)\n",
    "    print(y_true.dtype, y_pred.dtype)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:05:45.699736Z",
     "iopub.status.busy": "2022-02-16T16:05:45.699245Z",
     "iopub.status.idle": "2022-02-16T16:05:45.712899Z",
     "shell.execute_reply": "2022-02-16T16:05:45.712123Z",
     "shell.execute_reply.started": "2022-02-16T16:05:45.699698Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define our custom loss function.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import dill\n",
    "\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "\n",
    "def categorical_focal_loss(alpha, gamma=2.):\n",
    "    \"\"\"\n",
    "    Softmax version of focal loss.\n",
    "    When there is a skew between different categories/labels in your data set, you can try to apply this function as a\n",
    "    loss.\n",
    "           m\n",
    "      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
    "          c=1\n",
    "      where m = number of classes, c = class and o = observation\n",
    "    Parameters:\n",
    "      alpha -- the same as weighing factor in balanced cross entropy. Alpha is used to specify the weight of different\n",
    "      categories/labels, the size of the array needs to be consistent with the number of classes.\n",
    "      gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "      gamma -- 2.0 as mentioned in the paper\n",
    "      alpha -- 0.25 as mentioned in the paper\n",
    "    References:\n",
    "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
    "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
    "    Usage:\n",
    "     model.compile(loss=[categorical_focal_loss(alpha=[[.25, .25, .25]], gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "\n",
    "    alpha = np.array(alpha, dtype=np.float32)\n",
    "\n",
    "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred: A tensor resulting from a softmax\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        y_true, y_pred = np.argmax(y_true), np.argmax(y_pred)\n",
    "\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Calculate Cross Entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        # Calculate Focal Loss\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "        # Compute mean loss in mini_batch\n",
    "        return K.mean(K.sum(loss, axis=-1))\n",
    "\n",
    "    return categorical_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:05:46.784537Z",
     "iopub.status.busy": "2022-02-16T16:05:46.784266Z",
     "iopub.status.idle": "2022-02-16T16:05:46.80022Z",
     "shell.execute_reply": "2022-02-16T16:05:46.799523Z",
     "shell.execute_reply.started": "2022-02-16T16:05:46.784504Z"
    }
   },
   "outputs": [],
   "source": [
    "dframe_fundus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:05:47.395675Z",
     "iopub.status.busy": "2022-02-16T16:05:47.395403Z",
     "iopub.status.idle": "2022-02-16T16:05:47.417158Z",
     "shell.execute_reply": "2022-02-16T16:05:47.416352Z",
     "shell.execute_reply.started": "2022-02-16T16:05:47.395642Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reduce_mean(tf.square(tf.subtract(len(df_norm_filenames), len(dframe_fundus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:16:39.149423Z",
     "iopub.status.busy": "2022-02-16T16:16:39.148879Z",
     "iopub.status.idle": "2022-02-16T16:16:39.199526Z",
     "shell.execute_reply": "2022-02-16T16:16:39.198691Z",
     "shell.execute_reply.started": "2022-02-16T16:16:39.149374Z"
    },
    "id": "gAUbqGYSjwe6"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE=32\n",
    "\n",
    "# dframe_fundus = pd.concat([df_norm_filenames_random, df_cat_filenames, df_diabetes_dn,\n",
    "#                           df_glaucoma_dn, df_myopia_dn, df_hypertension, df_amd_dn,\n",
    "#                           df_others_dn]).reset_index(drop=True)\n",
    "\n",
    "N = float(len(df_norm_filenames_random)/len(dframe_fundus))\n",
    "C = float(len(df_cat_filenames)/len(dframe_fundus))\n",
    "G = float(len(df_glaucoma_dn)/len(dframe_fundus))\n",
    "D = float(len(df_diabetes_dn)/len(dframe_fundus))\n",
    "M = float(len(df_myopia_dn)/len(dframe_fundus))\n",
    "H = float(len(df_hypertension)/len(dframe_fundus))\n",
    "A = float(len(df_amd_dn)/len(dframe_fundus))\n",
    "O = float(len(df_others_dn)/len(dframe_fundus))\n",
    "\n",
    "# weights = tf.constant([0.2, 0.2, 0.2, 0.2])\n",
    "# weights = tf.constant([N, D, G, C, A, H, M, O])\n",
    "weights = tf.constant([N, C, G,  M])\n",
    "weights = tf.cast(weights, tf.float32)\n",
    "\n",
    "weighted_loss = weighted_categorical_crossentropy(weights)\n",
    "\n",
    "loss_fn = keras.losses.CategoricalCrossentropy()\n",
    "# focal_loss_categorical = categorical_focal_loss(gamma=2, alpha=[[.15,.15,.125,.125,.15,.15,.075, .075]])\n",
    "focal_loss_categorical = categorical_focal_loss(gamma=2, alpha=[[.30, .20, .20, .15, .15]])\n",
    "metrics = [\n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.AUC(name='auc')\n",
    "]\n",
    "\n",
    "\n",
    "rms_prop = keras.optimizers.RMSprop(lr=LR, decay=LR/NUM_EPOCHS)\n",
    "sgd_momentum = keras.optimizers.SGD(lr=0.01, decay=0.01/NUM_EPOCHS, \\\n",
    "                                    momentum=0.9, nesterov=True)\n",
    "adadelta = keras.optimizers.Adadelta()\n",
    "\n",
    "model.compile(loss=weighted_loss,\n",
    "              optimizer=rms_prop,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "phf98Jl3o0gO"
   },
   "source": [
    "# Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:20:10.157435Z",
     "iopub.status.busy": "2022-02-16T16:20:10.156714Z",
     "iopub.status.idle": "2022-02-16T16:20:11.739872Z",
     "shell.execute_reply": "2022-02-16T16:20:11.738408Z",
     "shell.execute_reply.started": "2022-02-16T16:20:10.157393Z"
    },
    "id": "-yeO70DJjwfB",
    "outputId": "4d1d8c93-7575-4b18-f60a-db9f901dbffd"
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "import traceback\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "checkpoint_dir = os.path.join(model_path, \"odir_checkpoint.ckpt\")\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                             monitor='val_accuracy',\n",
    "                                             mode='max',\n",
    "                                             save_best_only=True,\n",
    "                                             verbose=1)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               mode='auto',\n",
    "                                               min_delta=0,\n",
    "                                               patience=100,\n",
    "                                               restore_best_weights=True,\n",
    "                                               verbose=1)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                              mode='min',\n",
    "                                              min_delta=0.0001,\n",
    "                                              factor=0.1,\n",
    "                                              patience=140,\n",
    "                                              verbose=1)\n",
    "\n",
    "# model_hist = model.fit_generator(train_generator,\n",
    "#                                  epochs=NUM_EPOCHS,\n",
    "#                                  steps_per_epoch=(train_generator.samples // BATCH_SIZE),\n",
    "#                                  callbacks=[\n",
    "#                                             checkpoint,\n",
    "#                                             early_stopping\n",
    "#                                  ],\n",
    "#                                  validation_data=(valid_generator),\n",
    "#                                  validation_steps=(valid_generator.samples // BATCH_SIZE))\n",
    "# try:\n",
    "# model_hist = model.fit([x_train1, x_train2], y_train, \n",
    "#                        epochs=NUM_EPOCHS, \n",
    "#                        batch_size=BATCH_SIZE,\n",
    "#                        steps_per_epoch=((len(x_train1) + len(x_train2)) // BATCH_SIZE),\n",
    "#                        callbacks=[\n",
    "#                            checkpoint,\n",
    "#                            early_stopping\n",
    "#                        ],\n",
    "#                        verbose=1, shuffle=True, \n",
    "#                        validation_data = ([x_valid1, x_valid2], y_valid),\n",
    "#                        validation_steps=((len(x_valid1) + len(x_valid2)) // BATCH_SIZE))\n",
    "\n",
    "\n",
    "# try:\n",
    "model_hist = model.fit(x_train1, y_train1,\n",
    "                       epochs=NUM_EPOCHS,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       steps_per_epoch=((len(x_train1) // BATCH_SIZE)),\n",
    "                       callbacks=[\n",
    "                                  checkpoint,\n",
    "                                  early_stopping\n",
    "                       ],\n",
    "                       verbose=1,\n",
    "                       shuffle=True,\n",
    "                       validation_data=(x_valid1, y_valid1),\n",
    "                       validation_steps=(len(x_valid1) // BATCH_SIZE)\n",
    "                       )\n",
    "# except Exception as exc:\n",
    "#     traceback.print_tb(exc.__traceback__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "l0zJWq6flOF_"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T18:34:54.346193Z",
     "iopub.status.busy": "2022-02-13T18:34:54.345895Z",
     "iopub.status.idle": "2022-02-13T18:35:25.892676Z",
     "shell.execute_reply": "2022-02-13T18:35:25.891785Z",
     "shell.execute_reply.started": "2022-02-13T18:34:54.346157Z"
    },
    "id": "jX5ozMq1jwfn",
    "outputId": "10f40d67-6201-4950-98d6-70521b9ba09d"
   },
   "outputs": [],
   "source": [
    "_, train_acc, train_prec, train_auc = model.evaluate(x_train1, y_train1)\n",
    "_, test_acc, test_prec, test_auc = model.evaluate(x_test1, y_test1)\n",
    "\n",
    "print(\"Train Accuracy: {0: .2f}% - Train Precision: {1: .2f}% - Train AUC: {2:.2f}%\".format(train_acc * 100, train_prec * 100, train_auc * 100))\n",
    "print(\"Test Accuracy: {0:.2f}% - Test Precision: {1: .2f}% - Test AUC: {2: .2f}%\".format(test_acc * 100, test_prec * 100, test_auc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCBeTzYsIEtk"
   },
   "source": [
    "**For Custom Objects in Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-10T20:42:01.812029Z",
     "iopub.status.idle": "2022-02-10T20:42:01.812969Z",
     "shell.execute_reply": "2022-02-10T20:42:01.812761Z",
     "shell.execute_reply.started": "2022-02-10T20:42:01.812736Z"
    },
    "id": "vOvrtj_eID7J",
    "outputId": "feda8e6e-7481-4ef7-aa3a-d4d60a88f409"
   },
   "outputs": [],
   "source": [
    "# def crelu_fn(x):\n",
    "#   x = np.concatenate((x, -x), axis=1)\n",
    "#   return tf.nn.relu(x)\n",
    "\n",
    "# config = model.get_config()\n",
    "\n",
    "# custom_objects = {\"custom_activation\": tf.nn.crelu}\n",
    "# with keras.utils.custom_object_scope(custom_objects):\n",
    "#   model = keras.Model.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-10T20:42:01.814049Z",
     "iopub.status.idle": "2022-02-10T20:42:01.81491Z",
     "shell.execute_reply": "2022-02-10T20:42:01.814691Z",
     "shell.execute_reply.started": "2022-02-10T20:42:01.814666Z"
    },
    "id": "xtGTVUaSjwfs"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# model.save(os.path.join(model_path, \"odir_model-{0:.2f}\".format(test_acc)))\n",
    "# model.save_weights(os.path.join(model_path, \"odir_model-{0:.2f}-bw\".format(test_acc)))\n",
    "\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# tflite_model = converter.convert()\n",
    "# open(os.path.join(model_path, \"odir_model_four_{0:.2f}.tflite\".format(test_acc)), 'wb').write(tflite_model)\n",
    "# print(\"Model converted to TFLite Model!\")\n",
    "\n",
    "# tf.saved_model.save(model, model_path)\n",
    "# print(\"Saved model as SavedModel Format!\")\n",
    "\n",
    "# pickle_out = open(os.path.join(model_path, \"odir_history.h5\"), 'wb')\n",
    "# pickle.dump(saved_history, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, subfolders, filenames in os.walk(model_path):\n",
    "    for file in filenames:\n",
    "        print(os.path.join(dirname, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved pickle\n",
    "import pickle\n",
    "\n",
    "# pickle_in = open(os.path.join(model_path, \"odir_history.h5\"), \"rb\")\n",
    "pickle_in = open(odir_history_merged, \"rb\")\n",
    "saved_history = pickle.load(pickle_in)\n",
    "len(saved_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save(os.path.join(model_path, \"odir_model-{0:.2f}\".format(test_acc)))\n",
    "model.save_weights(os.path.join(model_path, \"odir_model-{0:.2f}-bw\".format(test_acc)))\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(os.path.join(model_path, \"odir_model_four_{0:.2f}.tflite\".format(test_acc)), 'wb').write(tflite_model)\n",
    "print(\"Model converted to TFLite Model!\")\n",
    "\n",
    "tf.saved_model.save(model, model_path)\n",
    "print(\"Saved model as SavedModel Format!\")\n",
    "\n",
    "pickle_out = open(os.path.join(model_path, \"odir_history.h5\"), 'wb')\n",
    "pickle.dump(saved_history, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmqZ-M3Djwf4"
   },
   "outputs": [],
   "source": [
    "# saved_history = model_hist.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "Zwl6wESBmbCM"
   },
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from IPython.display import FileLink\n",
    "model_obj = ZipFile(\"odir_rgb_merged_model_four-{0:.4f}.zip\".format(test_acc), \"w\")\n",
    "\n",
    "# for file in os.listdir(model_path):\n",
    "#   model_obj.write(os.path.join(model_path, file))\n",
    "\n",
    "for dirname, subfolders, filenames in os.walk(model_path):\n",
    "    for file in filenames:\n",
    "        model_obj.write(os.path.join(dirname, file))\n",
    "\n",
    "model_obj.close()\n",
    "FileLink(\"odir_rgb_merged_model_four-{0:.4f}.zip\".format(test_acc))\n",
    "# shutil.move(\"odir_model_eight-{0:.4f}.zip\".format(test_acc), \"/content/drive/MyDrive/Colab Notebooks/thesis/odir_model_eight-{0:.4f}.zip\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "duu8kgd4pF7i"
   },
   "source": [
    "# Step 7: Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T18:28:55.725953Z",
     "iopub.status.busy": "2022-02-13T18:28:55.725395Z",
     "iopub.status.idle": "2022-02-13T18:29:04.761335Z",
     "shell.execute_reply": "2022-02-13T18:29:04.759294Z",
     "shell.execute_reply.started": "2022-02-13T18:28:55.725915Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "custom_objects = {\"custom_activation\": tf.nn.crelu}\n",
    "# model = load_model(os.path.join(model_path, \"odir_checkpoint.h5\"), custom_objects=custom_objects)\n",
    "# model1 = load_model(os.path.join(model_path, \"odir_model-{0:.2f}\".format(test_acc)))\n",
    "model = load_model(odir_model_merged)\n",
    "# model1.load_weights(model_path, \"odir_model-{0:.2f}-bw\".format(test_acc))\n",
    "# model = load_model(odir_model_dir)\n",
    "\n",
    "# # model = tf.saved_model.load(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:02.124731Z",
     "iopub.status.busy": "2022-02-01T15:04:02.124147Z",
     "iopub.status.idle": "2022-02-01T15:04:02.136861Z",
     "shell.execute_reply": "2022-02-01T15:04:02.135924Z",
     "shell.execute_reply.started": "2022-02-01T15:04:02.12469Z"
    },
    "id": "ifjuiOOdjwgK"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "# define scatter plot visualization on plotly express\n",
    "\n",
    "NUM_EPOCHS = 150\n",
    "def display_training_curves(training, validation, yaxis):\n",
    "    if yaxis == \"loss\":\n",
    "        ylabel = \"Loss\"\n",
    "        title = \"Model Loss with respect to Epochs\"\n",
    "    elif yaxis == \"accuracy\":\n",
    "        ylabel = \"Accuracy\"\n",
    "        title = \"Model Accuracy with respect to Epochs\"\n",
    "    elif yaxis == \"precision\":\n",
    "        ylabel = \"Precision\"\n",
    "        title = \"Model Precision with respect to Epochs\"\n",
    "    elif yaxis == \"auc\":\n",
    "        ylabel = \"AUC\"\n",
    "        title = \"Model AUC with respect to Epochs\"\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x = np.arange(1, NUM_EPOCHS + 1, 1), mode='lines+markers',\n",
    "                  y=training, marker=dict(color='dodgerblue'), name='Training')\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=np.arange(1, NUM_EPOCHS + 1, 1), mode='lines+markers', y=validation, marker=dict(color='darkorange'),\n",
    "                  name='Validation')\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(title=title, yaxis_title=ylabel,\n",
    "                     xaxis_title='Epochs', template='plotly_white')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:02.13895Z",
     "iopub.status.busy": "2022-02-01T15:04:02.138198Z",
     "iopub.status.idle": "2022-02-01T15:04:03.014742Z",
     "shell.execute_reply": "2022-02-01T15:04:03.011558Z",
     "shell.execute_reply.started": "2022-02-01T15:04:02.138911Z"
    },
    "id": "rTEiuwjTpEKm",
    "outputId": "05f2e712-8dd1-4997-d540-738e77afb6e7"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "fig1, ax = plt.subplots(4, 1)\n",
    "plt.subplots_adjust(wspace=0, hspace=0.2)\n",
    "\n",
    "line1 = ax[0].plot(saved_history['accuracy'], label='Train Accuracy')\n",
    "line2 = ax[0].plot(saved_history['val_accuracy'], label=\"Test Accuracy\")\n",
    "plt.setp(line1, linewidth=2.0)\n",
    "plt.setp(line2, linewidth=2.0)\n",
    "ax[0].set_title(\"Model Accuracy\")\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "line1 = ax[1].plot(saved_history['loss'], label='Train Loss')\n",
    "line2 = ax[1].plot(saved_history['val_loss'], label='Test Loss')\n",
    "plt.setp(line1, linewidth=2.0)\n",
    "plt.setp(line2, linewidth=2.0)\n",
    "ax[1].set_title(\"Model Loss\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "\n",
    "line1 = ax[2].plot(saved_history['precision'], label='Train Precision')\n",
    "line2 = ax[2].plot(saved_history['val_precision'], label='Test Precision')\n",
    "plt.setp(line1, linewidth=2.0)\n",
    "plt.setp(line2, linewidth=2.0)\n",
    "ax[2].set_title(\"Model Precision\")\n",
    "ax[2].set_xlabel(\"Epochs\")\n",
    "ax[2].set_ylabel(\"Precision\")\n",
    "\n",
    "line1 = ax[3].plot(saved_history['auc'], label='Train AUC')\n",
    "line2 = ax[3].plot(saved_history['val_auc'], label='Test AUC')\n",
    "plt.setp(line1, linewidth=2.0)\n",
    "plt.setp(line2, linewidth=2.0)\n",
    "ax[3].set_title(\"Model AUC\")\n",
    "ax[3].set_xlabel(\"Epochs\")\n",
    "ax[3].set_ylabel(\"AUC\")\n",
    "\n",
    "for i in range(4):\n",
    "  ax[i].legend()\n",
    "\n",
    "fig1.canvas.set_window_title(\"Train vs Test\")\n",
    "fig1.set_figwidth(12)\n",
    "fig1.set_figheight(8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "mGqPdTWzjwgV"
   },
   "source": [
    "**Model Accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:03.017002Z",
     "iopub.status.busy": "2022-02-01T15:04:03.016462Z",
     "iopub.status.idle": "2022-02-01T15:04:03.3532Z",
     "shell.execute_reply": "2022-02-01T15:04:03.352495Z",
     "shell.execute_reply.started": "2022-02-01T15:04:03.016959Z"
    },
    "id": "SloO_oGijwgX",
    "outputId": "f88ffe31-2a77-4316-b0b0-9eda78743ab1"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 10\n",
    "plt.figure(figsize=(10, 4))\n",
    "line1 = plt.plot(saved_history['accuracy'], label='Train Accuracy')\n",
    "line2 = plt.plot(saved_history['val_accuracy'], label=\"Test Accuracy\")\n",
    "plt.setp(line1, linewidth=2.0)\n",
    "plt.setp(line2, linewidth=2.0)\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:03.354756Z",
     "iopub.status.busy": "2022-02-01T15:04:03.354369Z",
     "iopub.status.idle": "2022-02-01T15:04:03.848907Z",
     "shell.execute_reply": "2022-02-01T15:04:03.848206Z",
     "shell.execute_reply.started": "2022-02-01T15:04:03.354717Z"
    },
    "id": "ORtGnw6mjwgb",
    "outputId": "2f481d2f-91d7-4c46-94bd-07cf879da121"
   },
   "outputs": [],
   "source": [
    "display_training_curves(\n",
    "    saved_history['accuracy'],\n",
    "    saved_history['val_accuracy'],\n",
    "    'accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "rdcffDJ9jwgd"
   },
   "source": [
    "**Model Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:03.851067Z",
     "iopub.status.busy": "2022-02-01T15:04:03.850529Z",
     "iopub.status.idle": "2022-02-01T15:04:04.175964Z",
     "shell.execute_reply": "2022-02-01T15:04:04.175204Z",
     "shell.execute_reply.started": "2022-02-01T15:04:03.851027Z"
    },
    "id": "lS7bGJPUjwgf",
    "outputId": "3d7ead67-46b7-46ac-900d-e5a2dcf8b268"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 10\n",
    "plt.figure(figsize=(10, 4))\n",
    "line1 = plt.plot(saved_history['loss'], label='Train Loss')\n",
    "line2 = plt.plot(saved_history['val_loss'], label=\"Test Loss\")\n",
    "plt.setp(line1, linewidth=2.0)\n",
    "plt.setp(line2, linewidth=2.0)\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:04.178097Z",
     "iopub.status.busy": "2022-02-01T15:04:04.177284Z",
     "iopub.status.idle": "2022-02-01T15:04:04.214855Z",
     "shell.execute_reply": "2022-02-01T15:04:04.214019Z",
     "shell.execute_reply.started": "2022-02-01T15:04:04.178053Z"
    },
    "id": "bP6D_5gpjwgk",
    "outputId": "c3904be2-2ab2-47bb-f1ea-a0b4348d103c"
   },
   "outputs": [],
   "source": [
    "display_training_curves(\n",
    "    saved_history['loss'],\n",
    "    saved_history['val_loss'],\n",
    "    'loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "iAL1lQkDjwgl"
   },
   "source": [
    "**Model Precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:04.216709Z",
     "iopub.status.busy": "2022-02-01T15:04:04.216372Z",
     "iopub.status.idle": "2022-02-01T15:04:04.546867Z",
     "shell.execute_reply": "2022-02-01T15:04:04.546159Z",
     "shell.execute_reply.started": "2022-02-01T15:04:04.216671Z"
    },
    "id": "oTiaMQ-Sjwgn",
    "outputId": "397440e1-99fd-4d65-de96-b72365b92f30"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 10\n",
    "plt.figure(figsize=(10, 4))\n",
    "line1 = plt.plot(saved_history['precision'], label='Train Precision')\n",
    "line2 = plt.plot(saved_history['val_precision'], label=\"Test Preicison\")\n",
    "plt.setp(line1, linewidth=2.0)\n",
    "plt.setp(line2, linewidth=2.0)\n",
    "plt.title(\"Model Precision\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Precision\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:04.548409Z",
     "iopub.status.busy": "2022-02-01T15:04:04.547996Z",
     "iopub.status.idle": "2022-02-01T15:04:04.588669Z",
     "shell.execute_reply": "2022-02-01T15:04:04.588001Z",
     "shell.execute_reply.started": "2022-02-01T15:04:04.548372Z"
    },
    "id": "NgAHNFyUjwgt",
    "outputId": "8e1ba907-7a20-45eb-dc41-896b4d094320"
   },
   "outputs": [],
   "source": [
    "display_training_curves(\n",
    "    saved_history['precision'],\n",
    "    saved_history['val_precision'],\n",
    "    'precision'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "M3XKfcYvjwgu"
   },
   "source": [
    "**Model AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:04.590789Z",
     "iopub.status.busy": "2022-02-01T15:04:04.590289Z",
     "iopub.status.idle": "2022-02-01T15:04:04.929935Z",
     "shell.execute_reply": "2022-02-01T15:04:04.92912Z",
     "shell.execute_reply.started": "2022-02-01T15:04:04.590748Z"
    },
    "id": "8ps2q8Wgjwgv",
    "outputId": "ccec10c1-862f-4820-86b6-5fb691c73da7"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 10\n",
    "plt.figure(figsize=(10, 4))\n",
    "line1 = plt.plot(saved_history['auc'], label='Train AUC')\n",
    "line2 = plt.plot(saved_history['val_auc'], label=\"Test AUC\")\n",
    "plt.setp(line1, linewidth=2.0)\n",
    "plt.setp(line2, linewidth=2.0)\n",
    "plt.title(\"Model AUC\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"AUC\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:04.931812Z",
     "iopub.status.busy": "2022-02-01T15:04:04.931538Z",
     "iopub.status.idle": "2022-02-01T15:04:04.96641Z",
     "shell.execute_reply": "2022-02-01T15:04:04.96557Z",
     "shell.execute_reply.started": "2022-02-01T15:04:04.931775Z"
    },
    "id": "rTScQTDRjwg4",
    "outputId": "d2ff3a42-9f98-4b1a-8bf3-8fec3ae0edb5"
   },
   "outputs": [],
   "source": [
    "display_training_curves(\n",
    "    saved_history['auc'],\n",
    "    saved_history['val_auc'],\n",
    "    'auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "yxfgYuXNuVQ0"
   },
   "source": [
    "## Step 7.1: Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:04.968574Z",
     "iopub.status.busy": "2022-02-01T15:04:04.967993Z",
     "iopub.status.idle": "2022-02-01T15:04:04.972485Z",
     "shell.execute_reply": "2022-02-01T15:04:04.971665Z",
     "shell.execute_reply.started": "2022-02-01T15:04:04.968523Z"
    }
   },
   "outputs": [],
   "source": [
    "# class_labels = list(train_generator.class_indices.keys())\n",
    "# print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:04.974675Z",
     "iopub.status.busy": "2022-02-01T15:04:04.974097Z",
     "iopub.status.idle": "2022-02-01T15:04:04.982668Z",
     "shell.execute_reply": "2022-02-01T15:04:04.981866Z",
     "shell.execute_reply.started": "2022-02-01T15:04:04.974637Z"
    },
    "id": "0rUPGR50jwg9"
   },
   "outputs": [],
   "source": [
    "# class_labels = list(annot_df.iloc[:, -12:-4].sum().index)\n",
    "class_labels = ['N', 'C', 'G', 'M']\n",
    "# class_labels = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:04.984897Z",
     "iopub.status.busy": "2022-02-01T15:04:04.984321Z",
     "iopub.status.idle": "2022-02-01T15:04:10.508345Z",
     "shell.execute_reply": "2022-02-01T15:04:10.5061Z",
     "shell.execute_reply.started": "2022-02-01T15:04:04.984857Z"
    },
    "id": "QVJ5LMQEjwg-",
    "outputId": "997f5a06-22ea-4f2f-e295-11ad0b18146b"
   },
   "outputs": [],
   "source": [
    "# y_pred_raw = model.predict_generator(test_generator, verbose=1)\n",
    "y_pred_raw = model.predict(x_test1, verbose=1)\n",
    "y_pred = np.argmax(y_pred_raw, axis=1)\n",
    "\n",
    "y_test_classes = np.argmax(y_test1, axis=1)\n",
    "\n",
    "# print(\"Confusion Matrix\")\n",
    "# print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print(\"Classfication Report\")\n",
    "print(classification_report(y_test_classes, y_pred, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:10.51039Z",
     "iopub.status.busy": "2022-02-01T15:04:10.510088Z",
     "iopub.status.idle": "2022-02-01T15:04:10.990743Z",
     "shell.execute_reply": "2022-02-01T15:04:10.990009Z",
     "shell.execute_reply.started": "2022-02-01T15:04:10.510348Z"
    },
    "id": "z8BNGmbwjwg_",
    "outputId": "27fa62ff-3bc2-4c96-8b5c-5beb72123db5"
   },
   "outputs": [],
   "source": [
    "# y_pred_raw = model.predict_generator(test_generator, verbose=1)\n",
    "# y_pred_raw = model.predict(x_test, verbose=1)\n",
    "# y_pred = np.argmax(y_pred_raw, axis=1)\n",
    "\n",
    "# nb_test_samples = test_generator.samples\n",
    "# nb_train_samples = train_generator.samples\n",
    "\n",
    "y_test_classes = np.argmax(y_test1, axis=1)\n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "# cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "conf_mtrx = confusion_matrix(y_test_classes, y_pred)\n",
    "cm = np.around(conf_mtrx.astype('float') / conf_mtrx.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "# use white text if squares are dark; otherwise black\n",
    "threshold = cm.max() / 2\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "for i, j in itertools.product(range(cm.shape[1]), range(cm.shape[0])):\n",
    "  color = 'black' if cm[i, j] > threshold else \"white\"\n",
    "  plt.text(j, i, cm[i, j], horizontalalignment='center', color=color)\n",
    "\n",
    "plt.imshow(cm)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=90)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "plt.xlabel(\"True Label\")\n",
    "plt.ylabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:10.992271Z",
     "iopub.status.busy": "2022-02-01T15:04:10.991887Z",
     "iopub.status.idle": "2022-02-01T15:04:10.998078Z",
     "shell.execute_reply": "2022-02-01T15:04:10.997048Z",
     "shell.execute_reply.started": "2022-02-01T15:04:10.992234Z"
    }
   },
   "outputs": [],
   "source": [
    "print(conf_mtrx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Kappa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:11.000341Z",
     "iopub.status.busy": "2022-02-01T15:04:10.999962Z",
     "iopub.status.idle": "2022-02-01T15:04:11.017764Z",
     "shell.execute_reply": "2022-02-01T15:04:11.016763Z",
     "shell.execute_reply.started": "2022-02-01T15:04:11.00029Z"
    }
   },
   "outputs": [],
   "source": [
    "agreed = (conf_mtrx[0][0] + conf_mtrx[1][1] + conf_mtrx[2][2] + conf_mtrx[3][3]) / len(y_test)\n",
    "prob_true_N = float((conf_mtrx[0][0] + conf_mtrx[1][0] + conf_mtrx[2][0] + conf_mtrx[3][0]) / len(y_test))\n",
    "prob_pred_N = float((conf_mtrx[0][0] + conf_mtrx[0][1] + conf_mtrx[0][2] + conf_mtrx[0][3]) / len(y_test))\n",
    "chance_N = float(prob_true_N * prob_pred_N)\n",
    "\n",
    "prob_true_C = float((conf_mtrx[0][1] + conf_mtrx[1][1] + conf_mtrx[2][1] + conf_mtrx[3][1]) / len(y_test))\n",
    "prob_pred_C = float((conf_mtrx[1][0] + conf_mtrx[1][1] + conf_mtrx[1][2] + conf_mtrx[1][3]) / len(y_test))\n",
    "chance_C = float(prob_true_C * prob_pred_C)\n",
    "\n",
    "prob_true_G = float((conf_mtrx[0][2] + conf_mtrx[1][2] + conf_mtrx[2][2] + conf_mtrx[3][2]) / len(y_test))\n",
    "prob_pred_G = float((conf_mtrx[2][0] + conf_mtrx[2][1] + conf_mtrx[2][2] + conf_mtrx[2][3]) / len(y_test))\n",
    "chance_G = float(prob_true_G * prob_pred_G)\n",
    "\n",
    "prob_true_M = float((conf_mtrx[0][3] + conf_mtrx[1][3] + conf_mtrx[2][3] + conf_mtrx[3][3]) / len(y_test))\n",
    "prob_pred_M = float((conf_mtrx[3][0] + conf_mtrx[3][1] + conf_mtrx[3][2] + conf_mtrx[3][3]) / len(y_test))\n",
    "chance_M = float(prob_true_M * prob_pred_M)\n",
    "\n",
    "chance_agreed = float(chance_N + chance_C + chance_G + chance_M)\n",
    "\n",
    "kappa_score = float((agreed - chance_agreed)/(1-chance_agreed))\n",
    "print(\"Kappa Score: {0:.4f}\".format(kappa_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:11.01949Z",
     "iopub.status.busy": "2022-02-01T15:04:11.01891Z",
     "iopub.status.idle": "2022-02-01T15:04:11.032004Z",
     "shell.execute_reply": "2022-02-01T15:04:11.031142Z",
     "shell.execute_reply.started": "2022-02-01T15:04:11.019447Z"
    }
   },
   "outputs": [],
   "source": [
    "agreed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:11.034263Z",
     "iopub.status.busy": "2022-02-01T15:04:11.033778Z",
     "iopub.status.idle": "2022-02-01T15:04:11.074065Z",
     "shell.execute_reply": "2022-02-01T15:04:11.073213Z",
     "shell.execute_reply.started": "2022-02-01T15:04:11.034226Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Normal Evaluation\n",
    "N_tp = conf_mtrx[0][0]\n",
    "N_fn = (conf_mtrx[1][0] + conf_mtrx[2][0] + conf_mtrx[3][0])\n",
    "N_tn = (conf_mtrx[1][1] + conf_mtrx[1][2] + conf_mtrx[1][3] + \\\n",
    "        conf_mtrx[2][1] + conf_mtrx[2][2] + conf_mtrx[2][3] + \\\n",
    "        conf_mtrx[3][1] + conf_mtrx[3][2] + conf_mtrx[3][3])\n",
    "N_fp = (conf_mtrx[0][1] + conf_mtrx[0][2] + conf_mtrx[0][3])\n",
    "\n",
    "N_tpr = N_tp / (N_tp + N_fn)\n",
    "N_tnr = N_tn / (N_tn + N_fp)\n",
    "N_fpr = N_fp / (N_fp + N_tn)\n",
    "N_fnr = N_fn / (N_fn + N_tp)\n",
    "\n",
    "print(\"Normal Category: \")\n",
    "print(\"-->  True Positives: \", N_tp)\n",
    "print(\"-->  True Negatives: \", N_tn)\n",
    "print(\"-->  False Positives: \", N_fp)\n",
    "print(\"-->  False Negatives: \", N_fn)\n",
    "print('-'*32)\n",
    "print(\"-->  True Positive Rate: {0:.4f}\".format(N_tpr))\n",
    "print(\"-->  True Negative Rate: {0:.4f}\".format(N_tnr))\n",
    "print(\"-->  False Positive Rate: {0:.4f}\".format(N_fpr))\n",
    "print(\"-->  False Negative Rate: {0:.4f}\".format(N_fnr))\n",
    "\n",
    "print()\n",
    "print('=*=*'*8)\n",
    "print()\n",
    "\n",
    "# Cataract Evaluation\n",
    "C_tp = conf_mtrx[1][1]\n",
    "C_tn = (conf_mtrx[0][0] + conf_mtrx[0][2] + conf_mtrx[0][3] + \\\n",
    "        conf_mtrx[2][0] + conf_mtrx[2][2] + conf_mtrx[2][3] + \\\n",
    "        conf_mtrx[3][0] + conf_mtrx[3][2] + conf_mtrx[3][3])\n",
    "C_fp = (conf_mtrx[1][0] + conf_mtrx[1][2] + conf_mtrx[1][3])\n",
    "C_fn = (conf_mtrx[0][1] + conf_mtrx[2][1] + conf_mtrx[3][1])\n",
    "\n",
    "C_tpr = C_tp / (C_tp + C_fn)\n",
    "C_tnr = C_tn / (C_tn + C_fp)\n",
    "C_fpr = C_fp / (C_fp + C_tn)\n",
    "C_fnr = C_fn / (C_fn + C_tp)\n",
    "\n",
    "print(\"Cataract Category: \")\n",
    "print(\"-->  True Positives: \", C_tp)\n",
    "print(\"-->  True Negatives: \", C_tn)\n",
    "print(\"-->  False Positives: \", C_fp)\n",
    "print(\"-->  False Negatives: \", C_fn)\n",
    "print('-'*32)\n",
    "print(\"-->  True Positive Rate: {0:.4f}\".format(C_tpr))\n",
    "print(\"-->  True Negative Rate: {0:.4f}\".format(C_tnr))\n",
    "print(\"-->  False Positive Rate: {0:.4f}\".format(C_fpr))\n",
    "print(\"-->  False Negative Rate: {0:.4f}\".format(C_fnr))\n",
    "\n",
    "print()\n",
    "print('=*=*'*8)\n",
    "print()\n",
    "\n",
    "# Glaucoma Evaluation\n",
    "G_tp = conf_mtrx[2][2]\n",
    "G_tn = (conf_mtrx[0][0] + conf_mtrx[0][1] + conf_mtrx[0][3] + \\\n",
    "        conf_mtrx[1][0] + conf_mtrx[1][1] + conf_mtrx[1][3] + \\\n",
    "        conf_mtrx[3][0] + conf_mtrx[3][1] + conf_mtrx[3][3])\n",
    "G_fp = (conf_mtrx[2][0] + conf_mtrx[2][1] + conf_mtrx[2][3])\n",
    "G_fn = (conf_mtrx[0][2] + conf_mtrx[1][2] + conf_mtrx[3][2])\n",
    "\n",
    "G_tpr = G_tp / (G_tp + G_fn)\n",
    "G_tnr = G_tn / (G_tn + G_fp)\n",
    "G_fpr = G_fp / (G_fp + G_tn)\n",
    "G_fnr = G_fn / (G_fn + G_tp)\n",
    "\n",
    "print(\"Glaucoma Category: \")\n",
    "print(\"-->  True Positives: \", G_tp)\n",
    "print(\"-->  True Negatives: \", G_tn)\n",
    "print(\"-->  False Positives: \", G_fp)\n",
    "print(\"-->  False Negatives: \", G_fn)\n",
    "print('-'*32)\n",
    "print(\"-->  True Positive Rate: {0:.4f}\".format(G_tpr))\n",
    "print(\"-->  True Negative Rate: {0:.4f}\".format(G_tnr))\n",
    "print(\"-->  False Positive Rate: {0:.4f}\".format(G_fpr))\n",
    "print(\"-->  False Negative Rate: {0:.4f}\".format(G_fnr))\n",
    "\n",
    "print()\n",
    "print('=*=*'*8)\n",
    "print()\n",
    "\n",
    "# Myopia Evaluation\n",
    "M_tp = conf_mtrx[3][3]\n",
    "M_tn = (conf_mtrx[0][0] + conf_mtrx[0][1] + conf_mtrx[0][2] + \\\n",
    "        conf_mtrx[1][0] + conf_mtrx[1][1] + conf_mtrx[1][2] + \\\n",
    "        conf_mtrx[2][0] + conf_mtrx[2][1] + conf_mtrx[2][2])\n",
    "M_fp = (conf_mtrx[3][0] + conf_mtrx[3][1] + conf_mtrx[3][2])\n",
    "M_fn = (conf_mtrx[0][3] + conf_mtrx[1][3] + conf_mtrx[2][3])\n",
    "\n",
    "M_tpr = M_tp / (M_tp + M_fn)\n",
    "M_tnr = M_tn / (M_tn + M_fp)\n",
    "M_fpr = M_fp / (M_fp + M_tn)\n",
    "M_fnr = M_fn / (M_fn + M_tp)\n",
    "\n",
    "print(\"Myopia Category: \")\n",
    "print(\"-->  True Positives: \", M_tp)\n",
    "print(\"-->  True Negatives: \", M_tn)\n",
    "print(\"-->  False Positives: \", M_fp)\n",
    "print(\"-->  False Negatives: \", M_fn)\n",
    "print('-'*32)\n",
    "print(\"-->  True Positive Rate: {0:.4f}\".format(M_tpr))\n",
    "print(\"-->  True Negative Rate: {0:.4f}\".format(M_tnr))\n",
    "print(\"-->  False Positive Rate: {0:.4f}\".format(M_fpr))\n",
    "print(\"-->  False Negative Rate: {0:.4f}\".format(M_fnr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:11.07569Z",
     "iopub.status.busy": "2022-02-01T15:04:11.075169Z",
     "iopub.status.idle": "2022-02-01T15:04:11.093007Z",
     "shell.execute_reply": "2022-02-01T15:04:11.092093Z",
     "shell.execute_reply.started": "2022-02-01T15:04:11.075651Z"
    },
    "id": "KJy6xuaMjwhA",
    "outputId": "7fc174dc-c9af-43a7-de90-69cdadfc8a35"
   },
   "outputs": [],
   "source": [
    "def confusion_metrics(cm):\n",
    "#     TP = cm[1][0]\n",
    "#     TN = cm[0][1]\n",
    "#     FP = cm[0][0]\n",
    "#     FN = cm[1][1]\n",
    "\n",
    "    TP = (N_tp + C_tp + G_tp + M_tp)\n",
    "    TN = (N_tn + C_tn + G_tn + M_tn)\n",
    "    FP = (N_fp + C_fp + G_fp + M_fp)\n",
    "    FN = (N_fn + C_fn + G_fn + M_fn)\n",
    "    \n",
    "    TPR = TP / (TP + FN)\n",
    "    TNR = TN / (TN + FP)\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (FN + TP)\n",
    "    \n",
    "    print(\"True Positives: \", TP)\n",
    "    print(\"True Negatives: \", TN)\n",
    "    print(\"False Positives: \", FP)\n",
    "    print(\"False Negatives: \", FN)\n",
    "    print('-'*35)\n",
    "    print(\"True Positive Rate: {0:.4f}\".format(TPR))\n",
    "    print(\"True Negative Rate: {0:.4f}\".format(TNR))\n",
    "    print(\"False Positive Rate: {0:.4f}\".format(FPR))\n",
    "    print(\"False Negative Rate: {0:.4f}\".format(FNR))\n",
    "    \n",
    "    # calculate accuracy\n",
    "    conf_accuracy = (float(TP+TN) / float(TP + TN + FP + FN))\n",
    "    \n",
    "    # calculate mis-classification\n",
    "    conf_misclassification = 1 - conf_accuracy\n",
    "    \n",
    "    # calculate the sensitivity\n",
    "    conf_sensitivity = (TP / float(TP + FN))\n",
    "    \n",
    "    # calculate specificity\n",
    "    conf_specificity = (TN / float(TN + FP))\n",
    "    \n",
    "    # calculate precision\n",
    "    conf_precision = (TN / float(TN + FP))\n",
    "\n",
    "    # calculate f1 score\n",
    "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))\n",
    "    \n",
    "    print('-'*50)\n",
    "    print(f\"Accuracy: {round(conf_accuracy, 4)}\")\n",
    "    print(f\"Mis-Classification: {round(conf_misclassification, 4)}\")\n",
    "    print(f\"Sensitivity: {round(conf_sensitivity, 4)}\")\n",
    "    print(f\"Specificity: {round(conf_specificity,4)}\")\n",
    "    print(f\"G-Mean: {round(np.sqrt(round(conf_sensitivity,4) * round(conf_specificity, 4)), 4)}\")\n",
    "    print(f\"Precision: {round(conf_precision, 4)}\")\n",
    "    print(f\"F1 Score: {round(conf_f1, 4)}\")\n",
    "    \n",
    "confusion_metrics(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ6xtzrEjwhE"
   },
   "source": [
    "**Sensitivity (True Positive Rate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:11.095337Z",
     "iopub.status.busy": "2022-02-01T15:04:11.094597Z",
     "iopub.status.idle": "2022-02-01T15:04:16.229907Z",
     "shell.execute_reply": "2022-02-01T15:04:16.229187Z",
     "shell.execute_reply.started": "2022-02-01T15:04:11.095272Z"
    },
    "id": "xGslwIp6jwhF",
    "outputId": "8f89a7e9-80df-43f2-cac6-caf3c29ab361"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_raw = model.predict_generator(test_generator, verbose=1)\n",
    "y_pred_raw = model.predict(x_test1, verbose=1)\n",
    "y_pred_proba = np.amax(y_pred_raw, axis=1)\n",
    "\n",
    "y_test_classes = np.argmax(y_test1, axis=1)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "#     'true_values': test_generator.classes,\n",
    "    'true_values': y_test_classes,\n",
    "    'pred_probs': y_pred_proba\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "def TPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return (true_positive / (true_positive + false_negative))\n",
    "\n",
    "def FPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return 1 - (true_negative / (true_negative + false_positive))\n",
    "\n",
    "tpr_values = [TPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "fpr_values = [FPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "\n",
    "plt.plot(fpr_values, # False Positive Rate on x-axis\n",
    "         tpr_values, # True Positive Rate on y-axis\n",
    "         label='ROC Curve')\n",
    "\n",
    "plt.plot(np.linspace(0, 1, 200),\n",
    "         np.linspace(0, 1, 200),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "\n",
    "\n",
    "# plt.title(f\"ROC Curve with AUC = {round(metrics.roc_auc_score(pred_df['true_values'], pred_df['pred_probs']), 3)}\", fontsize=20)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qw6omzV5jwhH"
   },
   "source": [
    "**Specificity Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:16.232064Z",
     "iopub.status.busy": "2022-02-01T15:04:16.231503Z",
     "iopub.status.idle": "2022-02-01T15:04:21.403795Z",
     "shell.execute_reply": "2022-02-01T15:04:21.403042Z",
     "shell.execute_reply.started": "2022-02-01T15:04:16.232022Z"
    },
    "id": "xHGN5WYzjwhH",
    "outputId": "075943c6-8924-4c5c-90df-1ac48dce0ea5"
   },
   "outputs": [],
   "source": [
    "# y_pred_raw = model.predict_generator(test_generator, verbose=1)\n",
    "y_pred_raw = model.predict(x_test1, verbose=1)\n",
    "y_pred_proba = np.amax(y_pred_raw, axis=1)\n",
    "y_test_classes = np.argmax(y_test1, axis=1)\n",
    "pred_df = pd.DataFrame({\n",
    "    'true_values': y_test_classes,\n",
    "    'pred_probs': y_pred_proba\n",
    "})\n",
    "\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "def TNR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return (true_negative / (true_negative + false_positive))\n",
    "\n",
    "def FNR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return 1 - (true_positive / (true_positive + false_negative))\n",
    "\n",
    "tnr_values = [TNR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "fnr_values = [FNR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "\n",
    "plt.plot(fnr_values, # False Positive Rate on X-axis\n",
    "         tnr_values, # True Positive Rate on Y-axis\n",
    "         label='ROC Curve')\n",
    "\n",
    "plt.plot(np.linspace(0, 1, 200),\n",
    "         np.linspace(0, 1, 200),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "\n",
    "# plt.title(f\"ROC Curve with AUC = {round(metrics.roc_auc_score(pred_df['true_values'], pred_df['pred_probs']), 3)}\", fontsize=20)\n",
    "plt.ylabel('True Negative Rate', fontsize=16)\n",
    "plt.xlabel('False Negative Rate', fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vsp4PA6ojwhI"
   },
   "source": [
    "**Kappa Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:21.405866Z",
     "iopub.status.busy": "2022-02-01T15:04:21.405506Z",
     "iopub.status.idle": "2022-02-01T15:04:21.419515Z",
     "shell.execute_reply": "2022-02-01T15:04:21.418646Z",
     "shell.execute_reply.started": "2022-02-01T15:04:21.405824Z"
    },
    "id": "zOd7Z-q4jwhJ",
    "outputId": "18cc1bf9-04fc-44a1-fcae-a09976f92993"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from matplotlib.cbook import flatten\n",
    "\n",
    "th = 0.5\n",
    "# gt = (test_generator.classes)\n",
    "# gt = (np.argmax(y_test, axis=1))\n",
    "gt = np.argmax(y_test1, axis=1)\n",
    "pr = np.argmax(y_pred_raw, axis=1)\n",
    "kappa = metrics.cohen_kappa_score(gt,pr)\n",
    "# auc = metrics.roc_auc_score(gt, pr, multi_class='ovr')\n",
    "f1 = metrics.f1_score(gt, pr, average='micro')\n",
    "# final_score = (kappa + f1 + auc) / 3.0\n",
    "\n",
    "print(\"Evaluation Metrics: \")\n",
    "print(\"-> Kappa Score: {0:.4f}\".format(kappa))\n",
    "print(\"-> F1 Score: {0:.4f}\".format(f1))\n",
    "# print(\"-> AUC Score: {0:.4f}\".format(auc))\n",
    "# print(\"-> Final Score: {0:.4f}\".format(final_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTD6-N9iAXVf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukJGMgyZjwhK"
   },
   "source": [
    "**GRAD-CAM Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:21.421648Z",
     "iopub.status.busy": "2022-02-01T15:04:21.421105Z",
     "iopub.status.idle": "2022-02-01T15:04:21.428827Z",
     "shell.execute_reply": "2022-02-01T15:04:21.427985Z",
     "shell.execute_reply.started": "2022-02-01T15:04:21.421609Z"
    },
    "id": "z_QfYtPSjwhK",
    "outputId": "ad777ce3-c9f5-4544-ec70-f613ff2822d0"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "# def grad_cam(input_model, image, category_index, layer_name):\n",
    "#     model = keras.Sequential()\n",
    "#     model.add(input_model)\n",
    "    \n",
    "#     nb_classes = 2\n",
    "#     target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "#     model.add(layers.Lambda(target_layer, output_shape=target_category_loss_output_shape))\n",
    "    \n",
    "#     loss = K.sum(model.layers[-1].output)\n",
    "#     conv_output = [l for l in model.layers[0].layers if l.name is layer_name][0].output\n",
    "#     grads = normalize(K.gardients(loss, conv_output)[0])\n",
    "#     gradient_function = K.function([model.layers[0].input], [conv_output, grads])\n",
    "    \n",
    "#     output, grads_val, gradient_function([image])\n",
    "#     output, grads_val = output[0, :]. gards_val[0, :, :, :]\n",
    "    \n",
    "#     weights = np.mean(grads_val, axis=(0,1))\n",
    "#     cam = np.ones(output.shape[0 : 2], dtype=np.float32)\n",
    "    \n",
    "#     for i,w in enumerate(weights):\n",
    "#         cam += w * output[:, :, i]\n",
    "    \n",
    "#     cam = cv2.resize(cam, (256, 256))\n",
    "#     cam = np.maximum(cam, 0)\n",
    "#     heatmap = cam / np.max(cam)\n",
    "    \n",
    "#     # Return BGR [0...255] from the preprocessed image\n",
    "#     image = image[0, :]\n",
    "#     image -= np.min(image)\n",
    "#     image = np.minimum(image, 255)\n",
    "    \n",
    "#     cam = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "#     cam = np.float32(cam) + np.float32(image)\n",
    "#     cam = 255 * cam / np.max(cam)\n",
    "#     return np.uint8(cam), heatmap\n",
    "\n",
    "# cam, heatmap = grad_cam(model, preprocessed_input, predicted_class, \"block5_conv3\")\n",
    "# cv2.imwrite(\"gradcam.jpg\", cam)\n",
    "\n",
    "# regiter_gradient()\n",
    "# guided_model = modify_backprop(model, \"GuidedBackProp\")\n",
    "# saliency_fn = compile_salienfy_function(guded_model)\n",
    "# saliency = saliency_fn([preprocessed_input, 0])\n",
    "# gradcam = saliency[0] * heatmap[..., np.newaxis]\n",
    "# cv2.imwrite('guided_gradcam.jpg', deprocess_image(gradcam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:21.431028Z",
     "iopub.status.busy": "2022-02-01T15:04:21.430382Z",
     "iopub.status.idle": "2022-02-01T15:04:21.440107Z",
     "shell.execute_reply": "2022-02-01T15:04:21.439226Z",
     "shell.execute_reply.started": "2022-02-01T15:04:21.43086Z"
    },
    "id": "QeOm_a5bjwhL"
   },
   "outputs": [],
   "source": [
    "# define layers for producing heat maps\n",
    "\n",
    "last_conv_layer_name = \"conv2d_end\"\n",
    "classifier_layer_names = [\n",
    "    \"global_average_pooling2d\",\n",
    "    \"dense_output\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:21.441966Z",
     "iopub.status.busy": "2022-02-01T15:04:21.441679Z",
     "iopub.status.idle": "2022-02-01T15:04:21.455329Z",
     "shell.execute_reply": "2022-02-01T15:04:21.454237Z",
     "shell.execute_reply.started": "2022-02-01T15:04:21.441928Z"
    },
    "id": "8csashMyjwhM"
   },
   "outputs": [],
   "source": [
    "# define heatmap function helpers\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    # img is a PIL image of size 256x256\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size, color_mode='rgb')\n",
    "#     img_rgb = tf.keras.preprocessing.image.load_img(img_path, target_size=size, color_mode='rgb')\n",
    "    \n",
    "    # array is a float32 Numpy array of shape (256, 256, 1)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "#     array_rgb = tf.keras.preprocessing.image.img_to_array(img_rgb)\n",
    "    \n",
    "    # we add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 256, 256, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "#     array_rgb = np.expand_dims(array_rgb, axis=0)\n",
    "    \n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
    "    # first, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)\n",
    "    \n",
    "    # Second, we create a model that maps the actiavtions of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = tf.keras.Model(classifier_input, x)\n",
    "    \n",
    "    # Then, we compute the gradient of the top gradient class for our input image\n",
    "    # with respect to the actiavtions of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        \n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "        \n",
    "    # This is the gradient of the top predicted class with regards to \n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "    \n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # We multiply each channel in the feature map array\n",
    "    # by 'how important this channel is' with regards to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "        \n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "    \n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:21.457258Z",
     "iopub.status.busy": "2022-02-01T15:04:21.456985Z",
     "iopub.status.idle": "2022-02-01T15:04:21.481631Z",
     "shell.execute_reply": "2022-02-01T15:04:21.480649Z",
     "shell.execute_reply.started": "2022-02-01T15:04:21.457221Z"
    },
    "id": "PzSQi4IWjwhR"
   },
   "outputs": [],
   "source": [
    "# Sort validation set classes into arrays\n",
    "\n",
    "# total_batch = valid_generator.__len__()\n",
    "# valid_generator.reset()\n",
    "# normal_array = []\n",
    "# cataract_array = []\n",
    "\n",
    "# for i in range(total_batch):\n",
    "#     x, y = valid_generator.next()\n",
    "#     count = 0\n",
    "#     for _, label in y:\n",
    "#         if label == 1.0:\n",
    "#             normal_array.append(x[count])\n",
    "#         else:\n",
    "#             cataract_array.append(x[count])\n",
    "#         count += 1\n",
    "\n",
    "total_batch = len(x_test) // BATCH_SIZE\n",
    "normal_array = []\n",
    "cataract_array = []\n",
    "glaucoma_array = []\n",
    "amd_array =[]\n",
    "myopia_array = []\n",
    "\n",
    "normal_array1 = []\n",
    "cataract_array1 = []\n",
    "glaucoma_array1 = []\n",
    "amd_array1 =[]\n",
    "myopia_array1 = []\n",
    "b = 0\n",
    "\n",
    "for i in range(total_batch):\n",
    "  x, y = x_test1[b:b+BATCH_SIZE], y_test1[b:b+BATCH_SIZE]\n",
    "#   x_1, y_1 = x_test1[b:b+BATCH_SIZE], y_test1[b:b+BATCH_SIZE]\n",
    "  count = 0\n",
    "  for j in range(len(y)):\n",
    "    label = np.argmax(y[j])\n",
    "    if label == 0:\n",
    "      normal_array.append(x[count])\n",
    "#       normal_array1.append(x_1[count])\n",
    "    elif label == 1:\n",
    "      cataract_array.append(x[count])\n",
    "#       cataract_array1.append(x_1[count])\n",
    "    elif label == 2:\n",
    "      glaucoma_array.append(x[count])\n",
    "#       glaucoma_array1.append(x_1[count])\n",
    "    elif label == 3:\n",
    "      myopia_array.append(x[count])\n",
    "#       myopia_array1.append(x_1[count])\n",
    "    \n",
    "    count += 1\n",
    "  b += BATCH_SIZE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:21.483466Z",
     "iopub.status.busy": "2022-02-01T15:04:21.482909Z",
     "iopub.status.idle": "2022-02-01T15:04:21.49445Z",
     "shell.execute_reply": "2022-02-01T15:04:21.493503Z",
     "shell.execute_reply.started": "2022-02-01T15:04:21.483428Z"
    },
    "id": "yWUN8TU6ISyL",
    "outputId": "643272ab-58b3-48ba-edd5-4a30c1bb2538"
   },
   "outputs": [],
   "source": [
    "y_test1[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:21.496279Z",
     "iopub.status.busy": "2022-02-01T15:04:21.496Z",
     "iopub.status.idle": "2022-02-01T15:04:22.097186Z",
     "shell.execute_reply": "2022-02-01T15:04:22.096533Z",
     "shell.execute_reply.started": "2022-02-01T15:04:21.496242Z"
    },
    "id": "OlP2szTqI2Ru",
    "outputId": "5afd2dc2-010b-4671-b9f7-d2cac4f89142"
   },
   "outputs": [],
   "source": [
    "# idx 1 = normal\n",
    "# idx 2 = cataract\n",
    "# idx 7 = glaucoma\n",
    "# idx 4 = myopia\n",
    "\n",
    "# ['N', 'C', 'G', 'M']\n",
    "\n",
    "img = keras.preprocessing.image.array_to_img(x_test1[4])\n",
    "img_sample = np.expand_dims(x_test1[4], axis=0)\n",
    "# plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "plt.imshow(img)\n",
    "plt.title(f\"{class_labels[np.argmax(model.predict(img_sample))]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:22.099454Z",
     "iopub.status.busy": "2022-02-01T15:04:22.098726Z",
     "iopub.status.idle": "2022-02-01T15:04:22.200789Z",
     "shell.execute_reply": "2022-02-01T15:04:22.199988Z",
     "shell.execute_reply.started": "2022-02-01T15:04:22.099411Z"
    },
    "id": "zWka9ZW7Nyxb",
    "outputId": "bf12e388-01bd-4a79-f0a6-4a764dce40a7"
   },
   "outputs": [],
   "source": [
    "sample = np.expand_dims(x_test1[7],axis=0)\n",
    "inference = model.predict(sample)\n",
    "print(np.argmax(inference[0]))\n",
    "print(y_test1[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:22.202396Z",
     "iopub.status.busy": "2022-02-01T15:04:22.202118Z",
     "iopub.status.idle": "2022-02-01T15:04:22.22183Z",
     "shell.execute_reply": "2022-02-01T15:04:22.220735Z",
     "shell.execute_reply.started": "2022-02-01T15:04:22.202359Z"
    },
    "id": "Axga_XW-jwhZ"
   },
   "outputs": [],
   "source": [
    "# Define heatmap actiavtion display in a graph\n",
    "import matplotlib as mp\n",
    "\n",
    "def display_activation_graph(image_array, label):\n",
    "    # display predictions on validation set\n",
    "    plt.figure(figsize=(10, 10)) # specificying the overall grid size\n",
    "    correct = 0\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.14)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1) # the number of images in the grid is 4*5 (25)\n",
    "        pil_img = tf.keras.preprocessing.image.array_to_img(image_array[i])\n",
    "#         plt.imshow(pil_img, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.imshow(pil_img)\n",
    "        \n",
    "        inference = model.predict(np.array([image_array[i],]))\n",
    "        verdict = np.argmax(inference[0])\n",
    "        if verdict == label:\n",
    "            correct += 1\n",
    "            \n",
    "        plt.title(f\"{label} == {verdict}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"Model Prediction on Validation Set\\n {correct}/9 Correct\")\n",
    "    plt.show()\n",
    "    \n",
    "    # display heatmap\n",
    "    plt.figure(figsize=(10, 10)) # speciffying the overall grid size\n",
    "    correct = 0\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.14)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i+1) # the number of images in the grid is 4*5 (25)\n",
    "#         plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "        pil_img = tf.keras.preprocessing.image.array_to_img(image_array[i])\n",
    "        inference = model.predict(np.array([image_array[i],]))\n",
    "        heatmap = make_gradcam_heatmap(np.array([image_array[i],]),\n",
    "                                          model,\n",
    "                                          last_conv_layer_name,\n",
    "                                          classifier_layer_names\n",
    "                                      )\n",
    "        img = image_array[i]\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "        jet = mp.cm.get_cmap(\"jet\")\n",
    "        jet_colors = jet(np.arange(256))[:, :3]\n",
    "        jet_heatmap = jet_colors[heatmap]\n",
    "        jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "        jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "        jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "        superimposed_img = jet_heatmap * 0.4 + img\n",
    "        superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "        plt.imshow(superimposed_img)\n",
    "        verdict = np.argmax(inference[0])\n",
    "        if verdict == label:\n",
    "            correct += 1\n",
    "            \n",
    "        plt.title(f\"{label} == {verdict}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"Heat Map Representation \\n {correct}/9 Correct\")\n",
    "    plt.show()\n",
    "    \n",
    "    # display class activation \n",
    "    plt.figure(figsize=(10, 10)) # specifying the overall grid size\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.14)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    correct = 0\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3, i+1) # the number of images in the grid is 4*5 (25)\n",
    "        pil_img = tf.keras.preprocessing.image.array_to_img(image_array[i])\n",
    "        inference = model.predict(np.array([image_array[i],]))\n",
    "        heatmap = make_gradcam_heatmap(np.array([image_array[i],]),\n",
    "                                       model,\n",
    "                                       last_conv_layer_name,\n",
    "                                       classifier_layer_names\n",
    "                                      )\n",
    "        plt.imshow(heatmap)\n",
    "        verdict = np.argmax(inference[0])\n",
    "        if verdict == label:\n",
    "            correct += 1\n",
    "        plt.title(f\"{label} == {verdict}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"Class Activation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:22.223727Z",
     "iopub.status.busy": "2022-02-01T15:04:22.2234Z",
     "iopub.status.idle": "2022-02-01T15:04:31.441109Z",
     "shell.execute_reply": "2022-02-01T15:04:31.440353Z",
     "shell.execute_reply.started": "2022-02-01T15:04:22.223687Z"
    },
    "id": "DFfTCernjwhc",
    "outputId": "b4901bbb-3d86-4d20-cf35-4e0a096c7a73"
   },
   "outputs": [],
   "source": [
    "display_activation_graph(normal_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:31.443067Z",
     "iopub.status.busy": "2022-02-01T15:04:31.442619Z",
     "iopub.status.idle": "2022-02-01T15:04:39.787144Z",
     "shell.execute_reply": "2022-02-01T15:04:39.786357Z",
     "shell.execute_reply.started": "2022-02-01T15:04:31.443024Z"
    },
    "id": "nLmsFVqrjwhd"
   },
   "outputs": [],
   "source": [
    "display_activation_graph(cataract_array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:39.789742Z",
     "iopub.status.busy": "2022-02-01T15:04:39.788855Z",
     "iopub.status.idle": "2022-02-01T15:04:48.093252Z",
     "shell.execute_reply": "2022-02-01T15:04:48.092535Z",
     "shell.execute_reply.started": "2022-02-01T15:04:39.789691Z"
    },
    "id": "ZaykRqZGOpC6"
   },
   "outputs": [],
   "source": [
    "display_activation_graph(glaucoma_array, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:48.095038Z",
     "iopub.status.busy": "2022-02-01T15:04:48.094738Z",
     "iopub.status.idle": "2022-02-01T15:04:57.865107Z",
     "shell.execute_reply": "2022-02-01T15:04:57.864375Z",
     "shell.execute_reply.started": "2022-02-01T15:04:48.094999Z"
    },
    "id": "t6JfNHeHOtLa"
   },
   "outputs": [],
   "source": [
    "display_activation_graph(myopia_array, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:57.86747Z",
     "iopub.status.busy": "2022-02-01T15:04:57.866387Z",
     "iopub.status.idle": "2022-02-01T15:04:57.870869Z",
     "shell.execute_reply": "2022-02-01T15:04:57.870146Z",
     "shell.execute_reply.started": "2022-02-01T15:04:57.867426Z"
    }
   },
   "outputs": [],
   "source": [
    "# display_activation_graph(myopia_array, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "id": "VZ0Is06Lw6Y3"
   },
   "source": [
    "# Step 8: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:57.872878Z",
     "iopub.status.busy": "2022-02-01T15:04:57.872365Z",
     "iopub.status.idle": "2022-02-01T15:04:57.883488Z",
     "shell.execute_reply": "2022-02-01T15:04:57.882713Z",
     "shell.execute_reply.started": "2022-02-01T15:04:57.872837Z"
    }
   },
   "outputs": [],
   "source": [
    "X5[rand_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:57.885705Z",
     "iopub.status.busy": "2022-02-01T15:04:57.885062Z",
     "iopub.status.idle": "2022-02-01T15:04:58.307397Z",
     "shell.execute_reply": "2022-02-01T15:04:58.306635Z",
     "shell.execute_reply.started": "2022-02-01T15:04:57.885664Z"
    }
   },
   "outputs": [],
   "source": [
    "train_output = \"preprocess_train_gray\"\n",
    "class_labels = ['N', 'C','G','M']\n",
    "rand_idx = np.random.randint(0, len(x_test))\n",
    "X_min = x_test1[300:]\n",
    "# img_file = os.path.join(train_output, df_test.iloc[rand_idx, 0])\n",
    "img_file = x_test1[rand_idx]\n",
    "image = keras.preprocessing.image.array_to_img(img_file)\n",
    "# image = keras.preprocessing.image.load_img(img_file, color_mode='grayscale')\n",
    "x = keras.preprocessing.image.img_to_array(image)\n",
    "# x = x * 1./255\n",
    "x = np.expand_dims(x, axis=0)\n",
    "pred = model.predict(x)\n",
    "print(pred)\n",
    "\n",
    "plt.imshow(image)\n",
    "# plt.title(\"Original: \" + df_test.iloc[rand_idx, 1])\n",
    "plt.title(\"Original: \" + class_labels[np.argmax(y_test1[rand_idx])])\n",
    "plt.xlabel(\"Prediction: \" + class_labels[np.argmax(pred[0])])\n",
    "plt.grid(False)\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:04:58.309383Z",
     "iopub.status.busy": "2022-02-01T15:04:58.308958Z",
     "iopub.status.idle": "2022-02-01T15:05:00.025834Z",
     "shell.execute_reply": "2022-02-01T15:05:00.025193Z",
     "shell.execute_reply.started": "2022-02-01T15:04:58.309343Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "str_classes = ['Normal', 'Cataract', 'Glaucoma', 'Myopia']\n",
    "\n",
    "def draw_test(name, pred, im, true_label):\n",
    "  BLACK = [0, 0, 0]\n",
    "  expanded_image = cv2.copyMakeBorder(im, 0, 0, 10, 280, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "  cv2.putText(expanded_image, \"predicted: \" + pred, (280, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (51, 171, 249), 2)\n",
    "  cv2.putText(expanded_image, \"true: \" + true_label, (280, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 255, 0), 2)\n",
    "  return expanded_image\n",
    "\n",
    "# def getRandomImage(path, img_size=(256, 256)):\n",
    "#   # loads a random image\n",
    "#   rand_idx = np.random.randint(0, len(df_test))\n",
    "#   rand_file = df_test.iloc[rand_idx, 0]\n",
    "#   label = df_test.iloc[rand_idx, 1]\n",
    "#   label = str_classes[np.argmax(y_test[rand_idx])]\n",
    "#   image_path = os.path.join(path, rand_file)\n",
    "#   return image.load_img(image_path, target_size=img_size, color_mode='grayscale'), \\\n",
    "#           image_path, label, rand_file\n",
    "\n",
    "def getRandomImage(img_size=(256, 256)):\n",
    "  # loads random image\n",
    "  rand_idx = np.random.randint(0, len(x_test1))\n",
    "  rand_file = x_test[rand_idx]\n",
    "#   rand_file = df_test.iloc[rand_idx, 0]\n",
    "  img = x_test1[rand_idx]\n",
    "  label = str_classes[np.argmax(y_test1[rand_idx])]\n",
    "  img = keras.preprocessing.image.array_to_img(img)\n",
    "  return img, label, rand_idx, rand_file\n",
    "\n",
    "\n",
    "# we use a very low learning rate\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "axes = []\n",
    "files = []\n",
    "predictions = []\n",
    "true_labels = []\n",
    "rand_files = []\n",
    "rand_idxs = []\n",
    "rows = 9\n",
    "cols = 3\n",
    "\n",
    "# predicting the images\n",
    "\n",
    "for i in range(9):\n",
    "  # path = \"preprocess_train_gray\"\n",
    "  path = prep_train\n",
    "#   img, final_path, true_label, rand_file = getRandomImage(path)\n",
    "  img, true_label, rand_idx, rand_file = getRandomImage()\n",
    "#   files.append(final_path)\n",
    "  rand_files.append(rand_file)\n",
    "  rand_idxs.append(rand_idx)\n",
    "  true_labels.append(true_label)\n",
    "#   x = keras.preprocessing.image.img_to_array(img)\n",
    "  x = x_test1[rand_idx]\n",
    "#   x = img\n",
    "#   x = x * 1./255\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  predictions.append(classes)\n",
    "\n",
    "plt.rcParams['font.size'] = 6\n",
    "\n",
    "temp_path = \"temp_img\"\n",
    "\n",
    "if os.path.exists(temp_path):\n",
    "  clear_content(temp_path)\n",
    "else:\n",
    "  os.mkdir(temp_path)\n",
    "\n",
    "for i in range(len(rand_idxs)):\n",
    "  rgb_path = prep_train\n",
    "#   if rand_files[i] in os.listdir(prep_train):\n",
    "#         imgpath = os.path.join(rgb_path, rand_files[i])\n",
    "#   image = cv2.imread(files[i])\n",
    "  # image = cv2.imread(imgpath)\n",
    "  image = keras.preprocessing.image.array_to_img(x_test1[rand_idxs[i]])\n",
    "#   prep_img = cv2.imread(os.path.join(prep_train, df_test.iloc[rand_idxs[i], 0]))\n",
    "  image = cv2.imwrite(os.path.join(temp_path, f\"fundus_{rand_idxs[i]}.jpg\"), x_test1[rand_idxs[i]])\n",
    "#   image = cv2.imwrite(os.path.join(temp_path, f\"fundus_{rand_idxs[i]}.jpg\"), image)\n",
    "  image = cv2.imread(os.path.join(temp_path, f\"fundus_{rand_idxs[i]}.jpg\"))\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = draw_test(\"Prediction\", str_classes[np.argmax(predictions[i])], image, true_labels[i])\n",
    "  axes.append(fig.add_subplot(rows, cols, i+1))\n",
    "  plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "  plt.title(\"{0}: {1:.2f}%\".format(str_classes[np.argmax(predictions[i])], ((np.amax(predictions[i], 1)) * 100)[0]))\n",
    "  plt.grid(False)\n",
    "  plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:05:00.0379Z",
     "iopub.status.busy": "2022-02-01T15:05:00.037385Z",
     "iopub.status.idle": "2022-02-01T15:05:00.043012Z",
     "shell.execute_reply": "2022-02-01T15:05:00.042249Z",
     "shell.execute_reply.started": "2022-02-01T15:05:00.037843Z"
    },
    "id": "KJkpMB_1TOWO"
   },
   "outputs": [],
   "source": [
    "def round_up(n, decimals=0):\n",
    "  multiplier = 10 ** decimals\n",
    "  return np.ceil(n * multiplier) / multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:05:00.045062Z",
     "iopub.status.busy": "2022-02-01T15:05:00.044568Z",
     "iopub.status.idle": "2022-02-01T15:05:09.12752Z",
     "shell.execute_reply": "2022-02-01T15:05:09.126717Z",
     "shell.execute_reply.started": "2022-02-01T15:05:00.045023Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "folders = ['normal', 'cataract','glaucoma','myopia']\n",
    "test_folder = \"datazet/datazet\"\n",
    "n_count = 0\n",
    "i=0\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (25.0, 15.0)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "\n",
    "direc_path = os.path.join(test_folder, folders[0])\n",
    "for file in os.listdir(direc_path):\n",
    "    file_path = os.path.join(direc_path, file)\n",
    "    image = keras.preprocessing.image.load_img(file_path, color_mode=\"rgb\", target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    x = keras.preprocessing.image.img_to_array(image)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    pred = model.predict(x)\n",
    "#         print(pred)\n",
    "    prediction_class = folders[np.argmax(pred[0])]\n",
    "    true_class = folders[0]\n",
    "\n",
    "    plt.subplot(5, 10, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True: {true_class}\")\n",
    "    plt.xlabel(f\"Prediction: {prediction_class}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "    if true_class == prediction_class:\n",
    "        n_count+=1\n",
    "    i+=1\n",
    "plt.suptitle(f\"Normal Prediction on Test Images\\n {n_count}/50 Correct\")\n",
    "plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:05:09.12928Z",
     "iopub.status.busy": "2022-02-01T15:05:09.128906Z",
     "iopub.status.idle": "2022-02-01T15:05:19.717322Z",
     "shell.execute_reply": "2022-02-01T15:05:19.716376Z",
     "shell.execute_reply.started": "2022-02-01T15:05:09.129246Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (25.0, 15.0)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "i=0\n",
    "c_count = 0\n",
    "direc_path = os.path.join(test_folder, folders[1])\n",
    "for file in os.listdir(direc_path):\n",
    "    file_path = os.path.join(direc_path, file)\n",
    "    image = keras.preprocessing.image.load_img(file_path, color_mode=\"rgb\", target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    x = keras.preprocessing.image.img_to_array(image)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    pred = model.predict(x)\n",
    "#         print(pred)\n",
    "    prediction_class = folders[np.argmax(pred[0])]\n",
    "    true_class = folders[1]\n",
    "\n",
    "    plt.subplot(5, 10, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True: {true_class}\")\n",
    "    plt.xlabel(f\"Prediction: {prediction_class}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "    if true_class == prediction_class:\n",
    "        c_count+=1\n",
    "    i+=1\n",
    "plt.suptitle(f\"Cataract Prediction on Test Images\\n {c_count}/50 Correct\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:05:19.719236Z",
     "iopub.status.busy": "2022-02-01T15:05:19.718888Z",
     "iopub.status.idle": "2022-02-01T15:05:29.010219Z",
     "shell.execute_reply": "2022-02-01T15:05:29.009383Z",
     "shell.execute_reply.started": "2022-02-01T15:05:19.719197Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (25.0, 15.0)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "i=0\n",
    "g_count =0\n",
    "direc_path = os.path.join(test_folder, folders[2])\n",
    "for file in os.listdir(direc_path):\n",
    "    file_path = os.path.join(direc_path, file)\n",
    "    image = keras.preprocessing.image.load_img(file_path, color_mode=\"rgb\", target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    x = keras.preprocessing.image.img_to_array(image)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    pred = model.predict(x)\n",
    "#         print(pred)\n",
    "    prediction_class = folders[np.argmax(pred[0])]\n",
    "    true_class = folders[2]\n",
    "\n",
    "    plt.subplot(5, 10, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True: {true_class}\")\n",
    "    plt.xlabel(f\"Prediction: {prediction_class}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "    if true_class == prediction_class:\n",
    "        g_count+=1\n",
    "    i+=1\n",
    "plt.suptitle(f\"Glaucoma Prediction on Test Images\\n {g_count}/50 Correct\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:05:29.01254Z",
     "iopub.status.busy": "2022-02-01T15:05:29.012Z",
     "iopub.status.idle": "2022-02-01T15:05:39.006438Z",
     "shell.execute_reply": "2022-02-01T15:05:39.005396Z",
     "shell.execute_reply.started": "2022-02-01T15:05:29.012498Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (25.0, 15.0)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "\n",
    "i=0\n",
    "m_count = 0\n",
    "\n",
    "direc_path = os.path.join(test_folder, folders[3])\n",
    "for file in os.listdir(direc_path):\n",
    "    file_path = os.path.join(direc_path, file)\n",
    "    image = keras.preprocessing.image.load_img(file_path, color_mode=\"rgb\", target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    x = keras.preprocessing.image.img_to_array(image)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    pred = model.predict(x)\n",
    "#         print(pred)\n",
    "    prediction_class = folders[np.argmax(pred[0])]\n",
    "    true_class = folders[3]\n",
    "\n",
    "    plt.subplot(5, 10, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True: {true_class}\")\n",
    "    plt.xlabel(f\"Prediction: {prediction_class}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "    if true_class == prediction_class:\n",
    "        m_count+=1\n",
    "    i+=1\n",
    "plt.suptitle(f\"Myopia Prediction on Test Images\\n {m_count}/50 Correct\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:12:51.356412Z",
     "iopub.status.busy": "2022-02-01T15:12:51.35586Z",
     "iopub.status.idle": "2022-02-01T15:13:29.466953Z",
     "shell.execute_reply": "2022-02-01T15:13:29.465978Z",
     "shell.execute_reply.started": "2022-02-01T15:12:51.356367Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "folders = ['normal', 'cataract','glaucoma','myopia']\n",
    "test_folder = \"datazet/datazet\"\n",
    "n_count = 0\n",
    "c_count = 0\n",
    "m_count = 0\n",
    "g_count = 0\n",
    "i=0\n",
    "used_indices = []\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (25.0, 60.0)\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "\n",
    "for n in range(4):\n",
    "    direc_path = os.path.join(test_folder, folders[n])\n",
    "    for file in os.listdir(direc_path):\n",
    "        file_path = os.path.join(direc_path, file)\n",
    "        image = keras.preprocessing.image.load_img(file_path, color_mode=\"rgb\", target_size=(IMG_SIZE, IMG_SIZE))\n",
    "        x = keras.preprocessing.image.img_to_array(image)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        pred = model.predict(x)\n",
    "#         print(pred)\n",
    "        prediction_class = folders[np.argmax(pred[0])]\n",
    "        true_class = folders[n]\n",
    "        \n",
    "        plt.subplot(20, 10, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"True: {true_class}\")\n",
    "        plt.xlabel(f\"Prediction: {prediction_class}\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        ax = plt.gca()\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "        if folders[n] == prediction_class:\n",
    "            if folders[n] == 'normal':\n",
    "                n_count += 1\n",
    "            elif folders[n] == 'cataract':\n",
    "                c_count += 1\n",
    "            elif folders[n] == 'myopia':\n",
    "                m_count += 1\n",
    "            elif folders[n] == 'glaucoma':\n",
    "                g_count += 1\n",
    "        i+=1\n",
    "    if folders[n] == 'normal':\n",
    "        plt.suptitle(f\"Model Prediction on Test Images\\n {n_count}/50 Correct\")\n",
    "    elif folders[n] == 'cataract':\n",
    "        plt.suptitle(f\"Model Prediction on Test Images\\n {c_count}/50 Correct\")\n",
    "    elif folders[n] == 'glaucoma':\n",
    "        plt.suptitle(f\"Model Prediction on Test Images\\n {g_count}/50 Correct\")\n",
    "    elif folders[n] == 'myopia':\n",
    "        plt.suptitle(f\"Model Prediction on Test Images\\n {m_count}/50 Correct\")\n",
    "    \n",
    "plt.show()\n",
    "print(\"Test Summary:\")\n",
    "print('->Normal: {0}/50'.format(n_count))\n",
    "print('->Cataract: {0}/50'.format(c_count))\n",
    "print('->Myopia: {0}/50'.format(m_count))\n",
    "print('->Glaucoma: {0}/50'.format(g_count))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:22:28.11837Z",
     "iopub.status.busy": "2022-02-01T15:22:28.117673Z",
     "iopub.status.idle": "2022-02-01T15:22:28.198441Z",
     "shell.execute_reply": "2022-02-01T15:22:28.197563Z",
     "shell.execute_reply.started": "2022-02-01T15:22:28.118254Z"
    }
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(test_folder, folders[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:33:42.888801Z",
     "iopub.status.busy": "2022-02-01T15:33:42.888391Z",
     "iopub.status.idle": "2022-02-01T15:33:42.893733Z",
     "shell.execute_reply": "2022-02-01T15:33:42.892626Z",
     "shell.execute_reply.started": "2022-02-01T15:33:42.888766Z"
    },
    "id": "WFpnRXSMFGDG",
    "outputId": "910310c9-a665-4c9f-d0a7-acd450789263"
   },
   "outputs": [],
   "source": [
    "# from zipfile import ZipFile\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# zipped = \"odir_samples.zip\"\n",
    "# direc = \"temp_img\"\n",
    "# preds = \"preds\"\n",
    "\n",
    "# if os.path.exists(os.path.join(direc, preds)):\n",
    "#   clear_content(os.path.join(direc, preds))\n",
    "# else:\n",
    "#   os.mkdir(os.path.join(direc, preds))\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'labels': true_labels,\n",
    "#     'predictions': [np.argmax(pred) for pred in predictions]    \n",
    "# })\n",
    "\n",
    "# df.to_csv(os.path.join(direc, preds, \"predictions.csv\"))\n",
    "\n",
    "# with ZipFile(zipped, \"w\") as zipObj:\n",
    "#   for dirname, subfolders, filenames in os.walk(direc):\n",
    "#     for file in tqdm(filenames):\n",
    "#       zipObj.write(os.path.join(dirname, file))\n",
    "\n",
    "# print()\n",
    "# print(f\"{zipped} created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-01T15:36:59.218738Z",
     "iopub.status.busy": "2022-02-01T15:36:59.218465Z",
     "iopub.status.idle": "2022-02-01T15:36:59.222501Z",
     "shell.execute_reply": "2022-02-01T15:36:59.221511Z",
     "shell.execute_reply.started": "2022-02-01T15:36:59.218708Z"
    },
    "id": "CrTdDn6psftA"
   },
   "outputs": [],
   "source": [
    "# FileLink(\"odir_samples.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXzERj9nFArs"
   },
   "source": [
    "#### Convert TF model to TFLite and SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T19:12:11.94034Z",
     "iopub.status.busy": "2022-02-13T19:12:11.940073Z",
     "iopub.status.idle": "2022-02-13T19:12:20.18119Z",
     "shell.execute_reply": "2022-02-13T19:12:20.180484Z",
     "shell.execute_reply.started": "2022-02-13T19:12:11.940302Z"
    },
    "id": "lomG2SdxhBD9"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (25.0, 15.0)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "i=0\n",
    "g_count =0\n",
    "\n",
    "for file in tqdm(glaucoma_prepped):\n",
    "    image = keras.preprocessing.image.array_to_img(file)\n",
    "    x = keras.preprocessing.image.img_to_array(image)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    pred = model.predict(x)\n",
    "#         print(pred)\n",
    "    prediction_class = folders[np.argmax(pred[0])]\n",
    "    true_class = folders[2]\n",
    "\n",
    "    plt.subplot(5, 10, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"True: {true_class}\")\n",
    "    plt.xlabel(f\"Prediction: {prediction_class}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "    if true_class == prediction_class:\n",
    "        g_count+=1\n",
    "    i+=1\n",
    "plt.suptitle(f\"Glaucoma Prediction on Test Images\\n {g_count}/40 Correct\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
